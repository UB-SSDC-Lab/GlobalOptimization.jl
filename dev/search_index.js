var documenterSearchIndex = {"docs":
[{"location":"algs/pso/","page":"PSO","title":"PSO","text":"To be continued...","category":"page"},{"location":"lib/internal/temp/#Internals","page":"Internals","title":"Internals","text":"","category":"section"},{"location":"lib/internal/temp/","page":"Internals","title":"Internals","text":"Listing all non-exported types and functions here for now, but split off categories onto separate pages in the future!","category":"page"},{"location":"lib/internal/temp/#GlobalOptimization.AbstractAlgorithmSpecificOptions","page":"Internals","title":"GlobalOptimization.AbstractAlgorithmSpecificOptions","text":"AbstractAlgorithmSpecificOptions\n\nAbstract type for algorithm specific options\n\n\n\n\n\n","category":"type"},{"location":"lib/internal/temp/#GlobalOptimization.AbstractCandidate","page":"Internals","title":"GlobalOptimization.AbstractCandidate","text":"AbstractCandidate\n\nAbstract type for a candidate\n\n\n\n\n\n","category":"type"},{"location":"lib/internal/temp/#GlobalOptimization.AbstractEvaluator","page":"Internals","title":"GlobalOptimization.AbstractEvaluator","text":"AbstractEvaluator\n\nAbstract type for an evaluator. An evaluator is responsible for evaluating the fitness of a population or candidate.\n\n\n\n\n\n","category":"type"},{"location":"lib/internal/temp/#GlobalOptimization.AbstractMBHDistribution","page":"Internals","title":"GlobalOptimization.AbstractMBHDistribution","text":"AbstractMBHDistribution{T}\n\nAbstract type for MBH distributions.\n\n\n\n\n\n","category":"type"},{"location":"lib/internal/temp/#GlobalOptimization.AbstractNonlinearEquationProblem","page":"Internals","title":"GlobalOptimization.AbstractNonlinearEquationProblem","text":"AbstractNonlinearEquationProblem\n\nAbstract type for problems involving a set of nonlinear equations to solve.\n\n\n\n\n\n","category":"type"},{"location":"lib/internal/temp/#GlobalOptimization.AbstractOptimizationProblem","page":"Internals","title":"GlobalOptimization.AbstractOptimizationProblem","text":"AbstractOptimizationProblem\n\nAbstract type for optimization problems.\n\n\n\n\n\n","category":"type"},{"location":"lib/internal/temp/#GlobalOptimization.AbstractOptimizer","page":"Internals","title":"GlobalOptimization.AbstractOptimizer","text":"AbstractOptimizer\n\nAbstract type of all optimization algorithms.\n\n\n\n\n\n","category":"type"},{"location":"lib/internal/temp/#GlobalOptimization.AbstractOptions","page":"Internals","title":"GlobalOptimization.AbstractOptions","text":"AbstractOptions\n\nAbstract type for multiple options\n\n\n\n\n\n","category":"type"},{"location":"lib/internal/temp/#GlobalOptimization.AbstractPopulation","page":"Internals","title":"GlobalOptimization.AbstractPopulation","text":"AbstractPopulation\n\nAbstract type for a population of candidates.\n\n\n\n\n\n","category":"type"},{"location":"lib/internal/temp/#GlobalOptimization.AbstractProblem","page":"Internals","title":"GlobalOptimization.AbstractProblem","text":"AbstractProblem\n\nAbstract type for all solvable problems.\n\n\n\n\n\n","category":"type"},{"location":"lib/internal/temp/#GlobalOptimization.AsyncEvaluator","page":"Internals","title":"GlobalOptimization.AsyncEvaluator","text":"AsyncEvaluator\n\nAbstract type for an evaluator that evaluates the fitness of a single candidate asyncronously.\n\n\n\n\n\n","category":"type"},{"location":"lib/internal/temp/#GlobalOptimization.BatchEvaluator","page":"Internals","title":"GlobalOptimization.BatchEvaluator","text":"BatchEvaluator\n\nAbstract type for an evaluator that evaluates the fitness of an entire population.\n\n\n\n\n\n","category":"type"},{"location":"lib/internal/temp/#GlobalOptimization.DE","page":"Internals","title":"GlobalOptimization.DE","text":"DE\n\nDifferential Evolution (DE) algorithm.\n\n\n\n\n\n","category":"type"},{"location":"lib/internal/temp/#GlobalOptimization.DEBasePopulation","page":"Internals","title":"GlobalOptimization.DEBasePopulation","text":"DEBasePopulation{T <: AbstractFloat} <: AbstractPopulation{T}\n\nThe base representation of some population for the DE algorithms.\n\n\n\n\n\n","category":"type"},{"location":"lib/internal/temp/#GlobalOptimization.DECache","page":"Internals","title":"GlobalOptimization.DECache","text":"DECache\n\nCache for the DE algorithm.\n\n\n\n\n\n","category":"type"},{"location":"lib/internal/temp/#GlobalOptimization.DEOptions","page":"Internals","title":"GlobalOptimization.DEOptions","text":"DEOptions\n\nOptions for the Differential Evolution (DE) algorithms.\n\nFields:\n\ngeneral<:GeneralOptions: The general options.\nmutation_params<:AbstractMutationParameters: The mutation strategy parameters.\ncrossover_params<:AbstractCrossoverParameters: The crossover strategy parameters.\ninitial_space<:Union{Nothing,ContinuousRectangularSearchSpace}: The initial space to initialize the population.\nmax_iterations::Int: The maximum number of iterations.\nfunction_tolerance::Float64: The function tolerance for the stall condition.\nmax_stall_time::Float64: The maximum stall time for the stall condition.\nmax_stall_iterations::Int: The maximum number of stall iterations for the stall condition.\n\n\n\n\n\n","category":"type"},{"location":"lib/internal/temp/#GlobalOptimization.DEPopulation","page":"Internals","title":"GlobalOptimization.DEPopulation","text":"DEPopulation{T <: AbstractFloat} <: AbstractPopulation{T}\n\nThe full population representation for the DE algorithms, including both the candidates and the mutants.\n\n\n\n\n\n","category":"type"},{"location":"lib/internal/temp/#GlobalOptimization.DEPopulation-Tuple{Integer, Integer}","page":"Internals","title":"GlobalOptimization.DEPopulation","text":"DEPopulation(num_candidates::Integer, num_dims::Integer)\n\nConstructs a DEPopulation with num_candidates candidates in num_dims dimensions.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.FeasibilityHandlingEvaluator","page":"Internals","title":"GlobalOptimization.FeasibilityHandlingEvaluator","text":"FeasibilityHandlingEvaluator\n\nAn evaluator that handled a functions returned infeasibility penalty\n\n\n\n\n\n","category":"type"},{"location":"lib/internal/temp/#GlobalOptimization.FixedDimensionSearchSpace","page":"Internals","title":"GlobalOptimization.FixedDimensionSearchSpace","text":"FixedDimensionSearchSpace\n\nThe base abstract type for a search space with a fixed finite number of dimensions. Applicable to the vast majority of optimization problems.\n\n\n\n\n\n","category":"type"},{"location":"lib/internal/temp/#GlobalOptimization.GeneralOptions","page":"Internals","title":"GlobalOptimization.GeneralOptions","text":"GeneralOptions{display, function_value_check}\n\nGeneral options for all optimizers\n\n\n\n\n\n","category":"type"},{"location":"lib/internal/temp/#GlobalOptimization.MBH","page":"Internals","title":"GlobalOptimization.MBH","text":"MBH\n\nMonotonic Basin Hopping (MBH) algorithm.\n\nThis implementation employs a single candidate rather than a population.\n\n\n\n\n\n","category":"type"},{"location":"lib/internal/temp/#GlobalOptimization.MBH-Union{Tuple{has_penalty}, Tuple{SS}, Tuple{T}, Tuple{GlobalOptimization.AbstractProblem{has_penalty, SS}, GlobalOptimization.AbstractMBHDistribution{T}, GlobalOptimization.AbstractLocalSearch}} where {T<:Number, SS<:ContinuousRectangularSearchSpace{T}, has_penalty}","page":"Internals","title":"GlobalOptimization.MBH","text":"MBH(prob::AbstractOptimizationProblem{SS})\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.MBHAdaptiveDistribution","page":"Internals","title":"GlobalOptimization.MBHAdaptiveDistribution","text":"MBHAdaptiveDistribution{T}\n\nAdaptive distribution for MBH.\n\n\n\n\n\n","category":"type"},{"location":"lib/internal/temp/#GlobalOptimization.MBHOptions","page":"Internals","title":"GlobalOptimization.MBHOptions","text":"MBHOptions <: AbstractAlgorithmSpecificOptions\n\nOptions for the Monotonic Basin Hopping (MBH) algorithm.\n\n\n\n\n\n","category":"type"},{"location":"lib/internal/temp/#GlobalOptimization.MBHStaticDistribution","page":"Internals","title":"GlobalOptimization.MBHStaticDistribution","text":"MBHStaticDistribution{T}\n\nStatic distribution for MBH.\n\n\n\n\n\n","category":"type"},{"location":"lib/internal/temp/#GlobalOptimization.MBHStepMemory","page":"Internals","title":"GlobalOptimization.MBHStepMemory","text":"MBHStepMemory{T}\n\nMemory about MBH accepted steps. \n\n\n\n\n\n","category":"type"},{"location":"lib/internal/temp/#GlobalOptimization.NonlinearLeastSquaresProblem","page":"Internals","title":"GlobalOptimization.NonlinearLeastSquaresProblem","text":"NonlinearLeastSquaresProblem{has_penalty, SS, F, G}\n\nA nonlinear least squares problem. Contains the nonlinear equations and search space.\n\nFields\n\nf::F: The nonlinear equations.\ng!::G: The jacobian of the nonlinear equations.\nss::SS: The search space.\nn::Int: The number of residuals.\n\n\n\n\n\n","category":"type"},{"location":"lib/internal/temp/#GlobalOptimization.NonlinearLeastSquaresProblem-Union{Tuple{F}, Tuple{F, AbstractVector{<:Real}, AbstractVector{<:Real}, Int64}} where F<:Function","page":"Internals","title":"GlobalOptimization.NonlinearLeastSquaresProblem","text":"NonlinearLeastSquaresProblem(f, [g], LB, UB)\n\nConstructs a nonlinear least squares problem with nonlinear function f, optional Jacobian g, and a search space.\n\nArguments\n\nf::F: The nonlinear function.\ng::G: The Jacobian of the nonlinear function.\nLB::AbstractVector{<:Real}: The lower bounds of the search space.\nUB::AbstractVector{<:Real}: The upper bounds of the search space.\n\nReturns\n\nNonlinearLeastSquaresProblem{has_penalty, ContinuousRectangularSearchSpace, F, G}\n\nExamples\n\njulia> using GlobalOptimization;\njulia> f(x) = [x[1] - x[3], x[2] - x[3]]\njulia> LB = [-5.0, -5.0, -5.0];\njulia> UB = [ 5.0, 5.0, 5.0];\njulia> prob = NonlinearLeastSquaresProblem(f, ss, LB, UB, 2)\nNonlinearLeastSquaresProblem{Val{false}(), ContinuousRectangularSearchSpace{Float64}, typeof(f), Nothing}(f, nothing, ContinuousRectangularSearchSpace{Float64}([-5.0, -5.0, -5.0], [5.0, 5.0, 5.0], [10.0, 10.0, 10.0]), 2)\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.NonlinearLeastSquaresProblem-Union{Tuple{F}, Tuple{has_penalty}, Tuple{T}, Tuple{F, GlobalOptimization.SearchSpace{T}, Int64}} where {T, has_penalty, F<:Function}","page":"Internals","title":"GlobalOptimization.NonlinearLeastSquaresProblem","text":"NonlinearLeastSquaresProblem{has_penalty}(f::F, [g::G], ss::SS, num_resid::Int)\n\nConstructs a nonlinear least squares problem with nonlinear functions f, optional jacobian g, and search space ss. If has_penalty is specified as true, then the nonlinear function must return a Tuple{AbstractArray{T},T} for a given x of type AbstractArray{T}.\n\nArguments\n\nf::F: The nonlinear function.\ng::G: The Jacobian of the nonlinear function.\nss::SS: The search space.\nnum_resid::Int: The number of residuals.\n\nReturns\n\nNonlinearLeastSquaresProblem{has_penalty, SS, F, G}\n\nExamples\n\njulia> using GlobalOptimization;\njulia> f(x) = [x[1] - x[3], x[2] - x[3]]\njulia> LB = [-5.0, -5.0, -5.0];\njulia> UB = [ 5.0, 5.0, 5.0];\njulia> ss = ContinuousRectangularSearchSpace(LB, UB);\njulia> prob = NonlinearLeastSquaresProblem(f, ss, 2)\nNonlinearLeastSquaresProblem{Val{false}(), ContinuousRectangularSearchSpace{Float64}, typeof(f), Nothing}(f, nothing, ContinuousRectangularSearchSpace{Float64}([-5.0, -5.0, -5.0], [5.0, 5.0, 5.0], [10.0, 10.0, 10.0]), 2)\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.NonlinearLeastSquaresProblem-Union{Tuple{SS}, Tuple{F}, Tuple{F, SS, Int64}} where {F<:Function, SS<:GlobalOptimization.SearchSpace}","page":"Internals","title":"GlobalOptimization.NonlinearLeastSquaresProblem","text":"NonlinearLeastSquaresProblem(f, [g], ss)\n\nConstructs a nonlinear least squares problem with nonlinear function f, optional Jacobian g, and a search space.\n\nArguments\n\nf::F: The nonlinear function.\ng::G: The Jacobian of the nonlinear function.\nss::SS: The search space.\n\nReturns\n\nNonlinearLeastSquaresProblem{has_penalty, ContinuousRectangularSearchSpace, F, G}\n\nExamples\n\njulia> using GlobalOptimization;\njulia> f(x) = [x[1] - x[3], x[2] - x[3]]\njulia> LB = [-5.0, -5.0, -5.0];\njulia> UB = [ 5.0, 5.0, 5.0];\njulia> ss = ContinuousRectangularSearchSpace(LB, UB);\njulia> prob = NonlinearLeastSquaresProblem(f, ss, 2)\nNonlinearLeastSquaresProblem{Val{false}(), ContinuousRectangularSearchSpace{Float64}, typeof(f), Nothing}(f, nothing, ContinuousRectangularSearchSpace{Float64}([-5.0, -5.0, -5.0], [5.0, 5.0, 5.0], [10.0, 10.0, 10.0]), 2)\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.NonlinearProblem","page":"Internals","title":"GlobalOptimization.NonlinearProblem","text":"NonlinearProblem{has_penalty, SS, F, G}\n\nA nonlinear problem. Contains the nonlinear equations and search space.\n\nFields\n\nf::F: The nonlinear equations.\ng!::G: The jacobian of the nonlinear equations.\nss::SS: The search space.\n\n\n\n\n\n","category":"type"},{"location":"lib/internal/temp/#GlobalOptimization.NonlinearProblem-Union{Tuple{F}, Tuple{F, AbstractVector{<:Real}, AbstractVector{<:Real}}} where F<:Function","page":"Internals","title":"GlobalOptimization.NonlinearProblem","text":"NonlinearProblem(f, [g], LB, UB)\n\nConstructs a nonlinear problem with nonlinear function f, optional Jacobian g, and a continuous rectangular search space defined by the bounds LB and UB.\n\nArguments\n\nf::F: The nonlinear function.\ng::G: The Jacobian of the nonlinear function.\nLB::AbstractVector{<:Real}: The lower bounds of the search space.\nUB::AbstractVector{<:Real}: The upper bounds of the search space.\n\nReturns\n\nNonlinearProblem{has_penalty, ContinuousRectangularSearchSpace, F, G}\n\nExamples\n\njulia> using GlobalOptimization;\njulia> f(x) = [x[1] - 2.0, x[2] - 2.0]\njulia> LB = [-5.0, -5.0];\njulia> UB = [ 5.0, 5.0];\njulia> prob = NonlinearProblem(f, LB, UB)\nNonlinearProblem{Val{false}(), ContinuousRectangularSearchSpace{Float64}, typeof(f), Nothing}(f, nothing, ContinuousRectangularSearchSpace{Float64}([-5.0, -5.0], [5.0, 5.0], [10.0, 10.0]))\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.NonlinearProblem-Union{Tuple{F}, Tuple{has_penalty}, Tuple{T}, Tuple{F, GlobalOptimization.SearchSpace{T}}} where {T, has_penalty, F<:Function}","page":"Internals","title":"GlobalOptimization.NonlinearProblem","text":"NonlinearProblem{has_penalty}(f::F, [g::G], ss::SS)\n\nConstructs a nonlinear problem with nonlinear functions f, optional jacobian g, and search space ss. If has_penalty is specified as true, then the nonlinear function must return a Tuple{AbstractArray{T},T} for a given x of type AbstractArray{T}.\n\nArguments\n\nf::F: The nonlinear function.\ng::G: The Jacobian of the nonlinear function.\nss::SS: The search space.\n\nReturns\n\nNonlinearProblem{has_penalty, SS, F, G}\n\nExamples\n\njulia> using GlobalOptimization;\njulia> f(x) = [x[1] - 2.0, x[2] - 2.0]\njulia> LB = [-5.0, -5.0];\njulia> UB = [ 5.0, 5.0];\njulia> ss = ContinuousRectangularSearchSpace(LB, UB);\njulia> prob = NonlinearProblem(f, ss)\nNonlinearProblem{Val{false}(), ContinuousRectangularSearchSpace{Float64}, typeof(f), Nothing}(f, nothing, ContinuousRectangularSearchSpace{Float64}([-5.0, -5.0], [5.0, 5.0], [10.0, 10.0]))\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.NonlinearProblem-Union{Tuple{SS}, Tuple{F}, Tuple{F, SS}} where {F<:Function, SS<:GlobalOptimization.SearchSpace}","page":"Internals","title":"GlobalOptimization.NonlinearProblem","text":"NonlinearProblem(f, [g], ss)\n\nConstructs a nonlinear problem with nonlinear function f, optional Jacobian g, and a search space.\n\nArguments\n\nf::F: The nonlinear function.\ng::G: The Jacobian of the nonlinear function.\nss::SS: The search space.\n\nReturns\n\nNonlinearProblem{has_penalty, ContinuousRectangularSearchSpace, F, G}\n\nExamples\n\njulia> using GlobalOptimization;\njulia> f(x) = [x[1] - 2.0, x[2] - 2.0]\njulia> LB = [-5.0, -5.0];\njulia> UB = [ 5.0, 5.0];\njulia> ss = ContinuousRectangularSearchSpace(LB, UB);\njulia> prob = NonlinearProblem(f, ss)\nNonlinearProblem{Val{false}(), ContinuousRectangularSearchSpace{Float64}, typeof(f), Nothing}(f, nothing, ContinuousRectangularSearchSpace{Float64}([-5.0, -5.0], [5.0, 5.0], [10.0, 10.0]))\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.PSO","page":"Internals","title":"GlobalOptimization.PSO","text":"PSO\n\nParticle Swarm Optimization (PSO) algorithm.\n\n\n\n\n\n","category":"type"},{"location":"lib/internal/temp/#GlobalOptimization.PSOCache","page":"Internals","title":"GlobalOptimization.PSOCache","text":"PSOCache\n\nCache for PSO algorithm.\n\n\n\n\n\n","category":"type"},{"location":"lib/internal/temp/#GlobalOptimization.PSOOptions","page":"Internals","title":"GlobalOptimization.PSOOptions","text":"PSOOptions <: AbstractAlgorithmSpecificOptions\n\nOptions for the PSO algorithm.\n\n\n\n\n\n","category":"type"},{"location":"lib/internal/temp/#GlobalOptimization.PolyesterBatchEvaluator","page":"Internals","title":"GlobalOptimization.PolyesterBatchEvaluator","text":"PolyesterBatchEvaluator\n\nAn evaluator that evaluates the fitness of a population in parallel using multi-threading using Polyester.jl.\n\n\n\n\n\n","category":"type"},{"location":"lib/internal/temp/#GlobalOptimization.RectangularSearchSpace","page":"Internals","title":"GlobalOptimization.RectangularSearchSpace","text":"RectangularSearchSpace\n\nA FixedDimensionSearchSpace with N dimensional rectangle as the set of feasible points.\n\n\n\n\n\n","category":"type"},{"location":"lib/internal/temp/#GlobalOptimization.Results","page":"Internals","title":"GlobalOptimization.Results","text":"Results{T}\n\nA simple struct for returning results.\n\nFields\n\nfbest::T: The best function value found.\nxbest::Vector{T}: The best candidate found.\niters::Int: The number of iterations performed.\ntime::Float64: The time taken to perform the optimization in seconds.\nexitFlag::Int: The exit flag of the optimization.\n\n\n\n\n\n","category":"type"},{"location":"lib/internal/temp/#GlobalOptimization.Results-Union{Tuple{T}, Tuple{T, AbstractVector{T}, Any, Any, Any}} where T","page":"Internals","title":"GlobalOptimization.Results","text":"Results(fbest::T, xbest::AbstractVector{T}, iters, time, exitFlag)\n\nConstructs a new Results struct.\n\nArguments\n\nfbest::T: The best function value found.\nxbest::AbstractVector{T}: The best candidate found.\niters::Int: The number of iterations performed.\ntime::AbstractFloat: The time taken to perform the optimization in seconds.\nexitFlag::Int: The exit flag of the optimization.\n\nReturns\n\nResults{T}\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.SearchSpace","page":"Internals","title":"GlobalOptimization.SearchSpace","text":"SearchSpace\n\nThe base abstract type for a Problem search space. \n\n\n\n\n\n","category":"type"},{"location":"lib/internal/temp/#GlobalOptimization.SerialBatchEvaluator","page":"Internals","title":"GlobalOptimization.SerialBatchEvaluator","text":"SerialBatchEvaluator\n\nAn evaluator that evaluates the fitness of a population in serial.\n\n\n\n\n\n","category":"type"},{"location":"lib/internal/temp/#GlobalOptimization.SingleEvaluator","page":"Internals","title":"GlobalOptimization.SingleEvaluator","text":"SingleEvaluator\n\nAbstract type for an evaluator that evaluates the fitness of a single candidate\n\n\n\n\n\n","category":"type"},{"location":"lib/internal/temp/#GlobalOptimization.Swarm","page":"Internals","title":"GlobalOptimization.Swarm","text":"Swarm{T <: AbstractFloat} <: AbstractPopulation\n\nA population of particles for the PSO algorithm.\n\n\n\n\n\n","category":"type"},{"location":"lib/internal/temp/#GlobalOptimization.Swarm-Tuple{Integer, Integer}","page":"Internals","title":"GlobalOptimization.Swarm","text":"Swarm(num_particles::Integer, num_dims::Integer)\n\nConstructs a Swarm with num_particles particles in num_dims dimensions.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.ThreadedBatchEvaluator","page":"Internals","title":"GlobalOptimization.ThreadedBatchEvaluator","text":"ThreadedBatchEvaluator\n\nAn evaluator that evaluates the fitness of a population in parallel using multi-threading.\n\n\n\n\n\n","category":"type"},{"location":"lib/internal/temp/#Base.eachindex-Tuple{GlobalOptimization.AbstractPopulation}","page":"Internals","title":"Base.eachindex","text":"eachindex(pop::AbstractPopulation)\n\nReturns an iterator for the indices of the population.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#Base.length-Tuple{GlobalOptimization.AbstractPopulation}","page":"Internals","title":"Base.length","text":"length(pop::AbstractPopulation)\n\nReturns the number of candidates in the population.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#Base.size-Tuple{GlobalOptimization.AbstractPopulation}","page":"Internals","title":"Base.size","text":"size(pop::AbstractPopulation)\n\nReturns the size of the population.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.DEPopulation_F64-Tuple{Integer, Integer}","page":"Internals","title":"GlobalOptimization.DEPopulation_F64","text":"DEPopulation_F64(num_candidates::Integer, num_dims::Integer)\n\nConstructs a Float64 DEPopulation with num_candidate candidates in num_dims dimensions.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.Swarm_F32-Tuple{Integer, Integer}","page":"Internals","title":"GlobalOptimization.Swarm_F32","text":"Swarm_F32(num_particles::Integer, num_dims::Integer)\n\nConstructs a Float32 Swarm with num_particles particles in num_dims dimensions.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.Swarm_F64-Tuple{Integer, Integer}","page":"Internals","title":"GlobalOptimization.Swarm_F64","text":"Swarm_F64(num_particles::Integer, num_dims::Integer)\n\nConstructs a Float64 Swarm with num_particles particles in num_dims dimensions.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.candidate-Tuple{GlobalOptimization.AbstractCandidate}","page":"Internals","title":"GlobalOptimization.candidate","text":"candidate(c::AbstractCandidate)\n\nReturns the candidate c.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.candidates-Tuple{GlobalOptimization.AbstractPopulation}","page":"Internals","title":"GlobalOptimization.candidates","text":"candidates(pop::AbstractPopulation, [i::Integer])\n\nReturns the candidates from a population. If i is specified, returns the i-th candidate.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.check_fitness!-Union{Tuple{FVC}, Tuple{D}, Tuple{GlobalOptimization.AbstractCandidate, GlobalOptimization.GeneralOptions{D, FVC}}} where {D, FVC}","page":"Internals","title":"GlobalOptimization.check_fitness!","text":"check_fitness!(c::AbstractCandidate, options::Union{GeneralOptions,Val{true},Val{false}})\n\nChecks the fitness of the candidate c to ensure that it is valid iff options <: Union{GeneralOptions{D,Val{true}}, Val{true}}, otherwise, does nothing.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.check_fitness!-Union{Tuple{FVC}, Tuple{D}, Tuple{GlobalOptimization.AbstractPopulation, GlobalOptimization.GeneralOptions{D, FVC}}} where {D, FVC}","page":"Internals","title":"GlobalOptimization.check_fitness!","text":"check_fitness!(pop::AbstractPopulation, options::Union{GeneralOptions,Val{true},Val{false}})\n\nChecks the fitness of each candidate in the population pop to ensure that it is valid iff options <: Union{GeneralOptions{D,Val{true}}, Val{true}}, otherwise, does nothing.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.crossover!-Tuple{GlobalOptimization.DEPopulation, GlobalOptimization.AbstractBinomialCrossoverParameters, Any}","page":"Internals","title":"GlobalOptimization.crossover!","text":"crossover!(population::DEPopulation{T}, crossover_params, search_space)\n\nPerforms the crossover operation on the population population using the DE crossover strategy.\n\nThis function also ensures that, after crossover, the mutants are within the search space.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.dimdelta-Tuple{ContinuousRectangularSearchSpace}","page":"Internals","title":"GlobalOptimization.dimdelta","text":"dimdelta(ss::ContinuousRectangularSearchSpace{T}, [i::Integer])\n\nReturns the difference between the maximum and minimum values for the i-th dimension of ss. If i is not specified, returns a vector of all differences.\n\nArguments\n\nss::ContinuousRectangularSearchSpace{T}`\ni::Integer: the dimension to return the difference between the maximum and minimum values for.\n\nReturns\n\nT or Vector{T} the difference between the maximum and minimum values for the i-th dimension of ss or a vector of all differences if i not provided.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.dimmax-Tuple{ContinuousRectangularSearchSpace}","page":"Internals","title":"GlobalOptimization.dimmax","text":"dimmax(ss::ContinuousRectangularSearchSpace{T}, [i::Integer])\n\nReturns the maximum value for the i-th dimension of ss. If i is not specified, returns a vector of all maximum values.\n\nArguments\n\nss::ContinuousRectangularSearchSpace{T}\ni::Integer: the dimension to return the maximum value for.\n\nReturns\n\nT or Vector{T}: the minimum value for the i-th dimension of ss or a vector of all minimum values if i not provided.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.dimmin-Tuple{ContinuousRectangularSearchSpace}","page":"Internals","title":"GlobalOptimization.dimmin","text":"dimmin(ss::ContinuousRectangularSearchSpace{T}, [i::Integer])\n\nReturns the minimum value for the i-th dimension of ss. If i is not specified,  returns a vector of all minimum values.\n\nArguments\n\nss::RontinuousRectangularSearchSpace{T}\ni::Integer: the dimension to return the minimum value for.\n\nReturns\n\nT or Vector{T}: the minimum value for the i-th dimension of ss or a vector of all minimum values if i not provided.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.dimrange-Tuple{ContinuousRectangularSearchSpace}","page":"Internals","title":"GlobalOptimization.dimrange","text":"dimrange(ss::ContinuousRectangularSearchSpace{T}, [i::Integer])\n\nReturns the range of values for the i-th dimension of ss. If i is not specified, returns a vector of all ranges.\n\nArguments\n\nss::ContinuousRectangularSearchSpace{T}\ni::Integer: the dimension to return the range of values for.\n\nReturns\n\nTuple{T, T} or Vector{Tuple{T, T}}: the range of values for the i-th dimension of ss or a vector of all ranges if i not provided.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.display_status-Union{Tuple{FVC}, Tuple{D}, Tuple{Any, Any, Any, Any, GlobalOptimization.GeneralOptions{D, FVC}}} where {D, FVC}","page":"Internals","title":"GlobalOptimization.display_status","text":"display_status(time, iteration, stall_count, options)\n\nDisplays the status of the PSO algorithm.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.draw_step!-Union{Tuple{T}, Tuple{AbstractVector{T}, GlobalOptimization.MBHStaticDistribution{T}}} where T","page":"Internals","title":"GlobalOptimization.draw_step!","text":"draw_step!(step::AbstractVector{T}, dist::AbstractMBHDistribution{T})\n\nDraws a step from the distribution dist and stores it in step.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.draw_update!-Union{Tuple{T}, Tuple{GlobalOptimization.BasicHopper{T}, GlobalOptimization.AbstractMBHDistribution{T}}} where T","page":"Internals","title":"GlobalOptimization.draw_update!","text":"draw_update!(hopper::BasicHopper{T}, distribution::AbstractMBHDistribution{T})\n\nDraws a perterbation from distribution and updates candidate for the hopper hopper.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.enforce_bounds!-Union{Tuple{T}, Tuple{GlobalOptimization.Swarm{T}, ContinuousRectangularSearchSpace{T}}} where T","page":"Internals","title":"GlobalOptimization.enforce_bounds!","text":"enforce_bounds!(swarm::Swarm{T}, evaluator::BatchEvaluator)\n\nEnforces the bounds of the search space on each candidate in the swarm swarm. If a candidate\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.evaluate!-Tuple{GlobalOptimization.AbstractPopulation, GlobalOptimization.SerialBatchEvaluator}","page":"Internals","title":"GlobalOptimization.evaluate!","text":"evaluate!(pop::AbstractPopulation, evaluator::BatchEvaluator)\n\nEvaluates the fitness of a population using the given evaluator.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.evaluate_fitness!-Union{Tuple{T}, Tuple{GlobalOptimization.Swarm{T}, GlobalOptimization.BatchEvaluator{T}}} where T","page":"Internals","title":"GlobalOptimization.evaluate_fitness!","text":"evaluate_fitness!(swarm::Swarm{T}, evaluator::BatchEvaluator{T})\n\nEvaluates the fitness of each candidate in the swarm swarm using the evaluator. Updates the swarms best candidates if any are found.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.evaluate_with_penalty-Tuple{GlobalOptimization.FeasibilityHandlingEvaluator, AbstractArray}","page":"Internals","title":"GlobalOptimization.evaluate_with_penalty","text":"evaluate_with_penalty(evaluator::FeasibilityHandlingEvaluator, candidate::AbstractArray)\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.exprate-Tuple{T} where T<:AbstractFloat","page":"Internals","title":"GlobalOptimization.exprate","text":"exprate(λ::T)\n\nGenerate an exponential random variable with rate λ.\n\nArguments\n\nλ::AbstractFloat: the rate parameter of the exponential distribution.\n\nReturns\n\nval::T: an exponential random variable with rate λ. \n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.expscale-Tuple{T} where T<:AbstractFloat","page":"Internals","title":"GlobalOptimization.expscale","text":"expscale(β::T)\n\nGenerate an exponential random variable with scale β.\n\nArguments\n\nβ::AbstractFloat: the scale parameter of the exponential distribution.\n\nReturns\n\nval::T: an exponential random variable with scale β.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.feasible-Union{Tuple{T}, Tuple{AbstractVector{T}, ContinuousRectangularSearchSpace{T}}} where T","page":"Internals","title":"GlobalOptimization.feasible","text":"feasible(x, ss::ContinuousRectangularSearchSpace)\n\nReturns true if the point x is feasible in the search space ss, otherwise returns false.\n\nArguments\n\nx::AbstractVector{T}: the point to check for feasibility.\nss::ContinuousRectangularSearchSpace{T}: the search space to check for feasibility in.\n\nReturns\n\nBool: true if x is in ss, otherwise false.\n\nThrows\n\nDimensionMismatch: if x does not have the same number of dimensions as ss.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.fitness-Tuple{GlobalOptimization.AbstractCandidate}","page":"Internals","title":"GlobalOptimization.fitness","text":"fitness(c::AbstractCandidate)\n\nReturns the fitness of the candidate c.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.fitness-Tuple{GlobalOptimization.AbstractPopulation}","page":"Internals","title":"GlobalOptimization.fitness","text":"fitness(pop::AbstractPopulation, [i::Integer])\n\nReturns the fitness of the candidates from a population. If i is specified, returns the i-th fitness.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.get_display-Union{Tuple{GlobalOptimization.GeneralOptions{Val{true}, fvc}}, Tuple{fvc}} where fvc","page":"Internals","title":"GlobalOptimization.get_display","text":"get_display(opts::AbstractOptions)\n\nReturns the display option from an options type.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.get_display_interval-Tuple{GlobalOptimization.GeneralOptions}","page":"Internals","title":"GlobalOptimization.get_display_interval","text":"get_display_interval(opts::AbstractAlgorithmSpecificOptions)\n\nReturns the display interval from an algorithm options type.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.get_function_value_check-Tuple{GlobalOptimization.AbstractAlgorithmSpecificOptions}","page":"Internals","title":"GlobalOptimization.get_function_value_check","text":"get_function_value_check(opts::AbstractAlgorithmSpecificOptions)\n\nReturns the function value check option from an algorithm options type.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.get_general-Tuple{GlobalOptimization.AbstractAlgorithmSpecificOptions}","page":"Internals","title":"GlobalOptimization.get_general","text":"get_general(opts::AbstractAlgorithmSpecificOptions)\n\nReturns the general options from an algorithm options type.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.get_max_time-Tuple{GlobalOptimization.AbstractAlgorithmSpecificOptions}","page":"Internals","title":"GlobalOptimization.get_max_time","text":"get_max_time(opts::AbstractAlgorithmSpecificOptions)\n\nReturns the max time option from an algorithm options type.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.get_min_cost-Tuple{GlobalOptimization.AbstractAlgorithmSpecificOptions}","page":"Internals","title":"GlobalOptimization.get_min_cost","text":"get_min_cost(opts::AbstractAlgorithmSpecificOptions)\n\nReturns the min cost option from an algorithm options type.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.get_scalar_function-Tuple{GlobalOptimization.AbstractProblem}","page":"Internals","title":"GlobalOptimization.get_scalar_function","text":"get_scalar_function(prob::AbstractProblem)\n\nReturns cost function plus the infeasibility penalty squared as a scalar value.\nThis is used for PSO (GA, Differential Evolution, etc. if we ever get around to adding those)\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.get_scalar_function_with_penalty-Tuple{GlobalOptimization.AbstractProblem}","page":"Internals","title":"GlobalOptimization.get_scalar_function_with_penalty","text":"get_scalar_function_with_penalty(prob::AbstractProblem)\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.has_gradient-Tuple{GlobalOptimization.AbstractEvaluator}","page":"Internals","title":"GlobalOptimization.has_gradient","text":"has_gradient(evaluator::AbstractEvaluator)\n\nReturns true if the evaluator has a gradient, otherwise, false.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.initialize!-Union{Tuple{T}, Tuple{GlobalOptimization.BasicHopper{T}, ContinuousRectangularSearchSpace{T}, GlobalOptimization.FeasibilityHandlingEvaluator{T}}} where T","page":"Internals","title":"GlobalOptimization.initialize!","text":"initialize!(hopper::BasicHopper{T}, search_space::ContinuousRectangularSearchSpace{T})\n\nInitializes the hopper hopper with a uniform distribution in the search space.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.initialize_fitness!-Union{Tuple{T}, Tuple{GlobalOptimization.Swarm{T}, GlobalOptimization.BatchEvaluator{T}}} where T","page":"Internals","title":"GlobalOptimization.initialize_fitness!","text":"initialize_fitness!(swarm::Swarm{T}, evaluator::BatchEvaluator{T})\n\nInitializes the fitness of each candidate in the swarm swarm using the evaluator.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.initialize_uniform!-Union{Tuple{T}, Tuple{GlobalOptimization.Swarm{T}, ContinuousRectangularSearchSpace{T}}} where T","page":"Internals","title":"GlobalOptimization.initialize_uniform!","text":"initialize_uniform!(swarm::Swarm{T}, search_space::ContinuousRectangularSearchSpace{T})\n\nInitializes the swarm swarm with a uniform particle distribution in the search space.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.intersection-Union{Tuple{T2}, Tuple{T1}, Tuple{ContinuousRectangularSearchSpace{T1}, ContinuousRectangularSearchSpace{T2}}} where {T1, T2}","page":"Internals","title":"GlobalOptimization.intersection","text":"intersection(\n    ss1::ContinuousRectangularSearchSpace{T1}, \n    ss2::ContinuousRectangularSearchSpace{T2}\n)\n\nReturns the intersection of the two search spaces ss1 and ss2 as a new search space.\n\nArguments\n\nss1::ContinuousRectangularSearchSpace{T1}\nss2::ContinuousRectangularSearchSpace{T2}\n\nReturns\n\n`ContinuousRectangularSearchSpace{promote_type(T1, T2)}\n\nThrows\n\nDimensionMismatch: if ss1 and ss2 do not have the same number of dimensions.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.laplace-Tuple{T} where T","page":"Internals","title":"GlobalOptimization.laplace","text":"laplace(b::T)\n\nGenerate a Laplace random variable with location 0.0 and scale b.\n\nArguments\n\nb::AbstractFloat: the scale parameter of the Laplace distribution.\n\nReturns\n\nval::T: a Laplace random variable with location 0.0 and scale b.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.laplace-Union{Tuple{Type{T}}, Tuple{T}} where T","page":"Internals","title":"GlobalOptimization.laplace","text":"laplace([::Type{T}]) where T <: AbstractFloat\n\nGenerate a Laplace random variable with location 0.0 and scale 1.0. If T is specified, the random variable will be of type T.\n\nArguments\n\nT::Type{T}: the type of the random variable to generate. If not specified, Float64 is used.\n\nReturns\n\nval::T: a Laplace random variable with location 0.0 and scale 1.0\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.laplace-Union{Tuple{T}, Tuple{T, T}} where T<:AbstractFloat","page":"Internals","title":"GlobalOptimization.laplace","text":"laplace(μ::AbstractFloat, b::Real)\n\nGenerate a Laplace random variable with location μ and scale b.\n\nArguments\n\nμ::AbstractFloat: the location parameter of the Laplace distribution.\nb::Real: the scale parameter of the Laplace distribution.\n\nReturns\n\nval::T: a Laplace random variable with location μ and scale b.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.mutate!-Union{Tuple{MP}, Tuple{GlobalOptimization.DEPopulation, MP, Any}} where MP<:GlobalOptimization.AbstractMutationParameters","page":"Internals","title":"GlobalOptimization.mutate!","text":"mutate!(population::DEPopulation{T}, F, best_candidate)\n\nMutates the population population using the DE mutation strategy.\n\nThis is an implementation of the unified mutation strategy proposed by Ji Qiang and Chad Mitchell in \"A Unified Differential Evolution Algorithm for Global Optimization\".\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.numdims-Tuple{ContinuousRectangularSearchSpace}","page":"Internals","title":"GlobalOptimization.numdims","text":"numdims(ss::ContinuousRectangularSearchSpace)\n\nReturns the number of dimensions in the search space ss.\n\nArguments\n\nss::ContinuousRectangularSearchSpace\n\nReturns\n\nInteger\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.numdims-Tuple{GlobalOptimization.AbstractProblem}","page":"Internals","title":"GlobalOptimization.numdims","text":"numdims(prob::AbstractProblem)\n\nReturns the number of dimensions of the decision vector of the optimization problem prob.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.push!-Union{Tuple{T}, Tuple{GlobalOptimization.MBHStepMemory{T}, AbstractVector{T}, T, T}} where T","page":"Internals","title":"GlobalOptimization.push!","text":"push!(step_memory::MBHStepMemoory{T}, step::Vector{T}, pre_step_fitness::T, post_step_fitness::T)\n\nPushes a step into the step memory.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.push_accepted_step!-Union{Tuple{T}, Tuple{GlobalOptimization.MBHAdaptiveDistribution{T}, AbstractVector{T}, T, T}} where T","page":"Internals","title":"GlobalOptimization.push_accepted_step!","text":"push_accepted_step!(\n    dist::MBHAdaptiveDistribution{T}, \n    step::AbstractVector{T}, \n    pre_step_fitness::T, \n    post_step_fitness::T,\n) where {T}\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.scalar_function-Union{Tuple{G}, Tuple{F}, Tuple{SS}, Tuple{has_penalty}, Tuple{OptimizationProblem{has_penalty, SS, F, G}, AbstractArray}} where {has_penalty, SS, F, G}","page":"Internals","title":"GlobalOptimization.scalar_function","text":"scalar_function(prob::OptimizationProblem, x::AbstractArray)\n\nEvaluates the objective function f of the optimization problem prob at x and returns the cost function plus half the infeasibility squared.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.scalar_function-Union{Tuple{has_penalty}, Tuple{GlobalOptimization.AbstractNonlinearEquationProblem{has_penalty}, AbstractArray}} where has_penalty","page":"Internals","title":"GlobalOptimization.scalar_function","text":"scalar_function(prob::AbstractNonlinearEquationProblem, x::AbstractArray)\n\nEvaluates the set of nonlinear equations f and returns the nonlinear least squares cost plus half the infeasibility squared.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.scalar_function_with_penalty-Union{Tuple{G}, Tuple{F}, Tuple{SS}, Tuple{has_penalty}, Tuple{OptimizationProblem{has_penalty, SS, F, G}, AbstractArray}} where {has_penalty, SS, F, G}","page":"Internals","title":"GlobalOptimization.scalar_function_with_penalty","text":"scalar_function_with_penalty(prob::OptimizationProblem, x::AbstractArray)\n\nEvaluates the objective function f of the optimization problem prob at x and returns the cost function and the infeasibility penalty term as tuple. i.e., for an OptimizationProblem, this is simply the original function.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.scalar_function_with_penalty-Union{Tuple{has_penalty}, Tuple{GlobalOptimization.AbstractNonlinearEquationProblem{has_penalty}, AbstractArray}} where has_penalty","page":"Internals","title":"GlobalOptimization.scalar_function_with_penalty","text":"scalar_function_with_penalty(prob::AbstractNonlinearEquationProblem, x::AbstractArray)\n\nEvaluates the set of nonlinear equations f and returns the nonlinear least squares cost and the infeasibility penalty term as a tuple.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.search_space-Tuple{GlobalOptimization.AbstractProblem}","page":"Internals","title":"GlobalOptimization.search_space","text":"search_space(prob::AbstractProblem)\n\nReturns the search space of the optimization problem prob.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.selection!-Tuple{GlobalOptimization.DEPopulation}","page":"Internals","title":"GlobalOptimization.selection!","text":"selection!(population::DEPopulation{T}, evaluator::BatchEvaluator{T})\n\nReplace candidates with mutants if they have a better fitness.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.set_fitness!-Tuple{GlobalOptimization.AbstractCandidate, Any}","page":"Internals","title":"GlobalOptimization.set_fitness!","text":"set_fitness!(c::AbstractCandidate, fitness)\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.set_fitness!-Tuple{GlobalOptimization.AbstractPopulation, Vector}","page":"Internals","title":"GlobalOptimization.set_fitness!","text":"set_fitness(pop::AbstractPopulation, fitness, [i::Integer])\n\nSets the fitness of the candidates from a population. If i is specified, sets the i-th fitness.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.stalled-Tuple{GlobalOptimization.PSO, Any}","page":"Internals","title":"GlobalOptimization.stalled","text":"stalled(pso::PSO, stall_value)\n\nReturns true if the PSO algorithm pso is stalled, false otherwise.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.step!-Tuple{GlobalOptimization.Swarm}","page":"Internals","title":"GlobalOptimization.step!","text":"step!(swarm::Swarm)\n\nSteps the swarm swarm forward one iteration.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.step_std-Union{Tuple{T}, Tuple{GlobalOptimization.MBHStepMemory{T}, Integer}} where T","page":"Internals","title":"GlobalOptimization.step_std","text":"step_std(step_memory::MBHStepMemory{T}, var_idx::Integer)\n\nReturns the standard deviation of the step memory. If var_idx is specified, then the standard deviation  of the step memory for the variable at index var_idx is returned.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.update_fitness!-Union{Tuple{T}, Tuple{GlobalOptimization.BasicHopper{T}, GlobalOptimization.MBHStaticDistribution{T}}} where T","page":"Internals","title":"GlobalOptimization.update_fitness!","text":"update_fitness!(hopper::BasicHopper{T}, distribution::AbstractMBHDistribution{T})\n\nUpdates the hopper fitness information after previously evaluating the fitness of the hopper.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.update_global_best!-Tuple{GlobalOptimization.PSO}","page":"Internals","title":"GlobalOptimization.update_global_best!","text":"update_global_best!(pso::PSO)\n\nUpdates the global best candidate in the PSO algorithm pso if a better candidate is found.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.update_inertia-Tuple{Any, Any, Any}","page":"Internals","title":"GlobalOptimization.update_inertia","text":"update_inertia(inertia, range, stall_count)\n\nReturns new inertia weight based on the current 'inertia', the range, and stall_count.\n\n\n\n\n\n","category":"method"},{"location":"lib/internal/temp/#GlobalOptimization.update_velocity!-Union{Tuple{T}, Tuple{GlobalOptimization.Swarm{T}, Vararg{Any, 5}}} where T","page":"Internals","title":"GlobalOptimization.update_velocity!","text":"update_velocity!(swarm::Swarm{T}, cache::Cache, ns::Integer, w, y1, y2)\n\nUpdates the velocity of each candidate in the swarm swarm,\n\n\n\n\n\n","category":"method"},{"location":"algs/de/","page":"DE","title":"DE","text":"To be continued...","category":"page"},{"location":"algs/mbh/","page":"MBH","title":"MBH","text":"Not implemented...","category":"page"},{"location":"lib/public/#Public-API-Documentation","page":"Public API","title":"Public API Documentation","text":"","category":"section"},{"location":"lib/public/","page":"Public API","title":"Public API","text":"Documentation for GlobalOptimization's public interface.","category":"page"},{"location":"lib/public/#Contents","page":"Public API","title":"Contents","text":"","category":"section"},{"location":"lib/public/","page":"Public API","title":"Public API","text":"Pages = [\"public.md\"]\nDepth = 2:3","category":"page"},{"location":"lib/public/#Index","page":"Public API","title":"Index","text":"","category":"section"},{"location":"lib/public/","page":"Public API","title":"Public API","text":"Pages = [\"public.md\"]","category":"page"},{"location":"lib/public/#Optimization-Problem","page":"Public API","title":"Optimization Problem","text":"","category":"section"},{"location":"lib/public/#GlobalOptimization.OptimizationProblem","page":"Public API","title":"GlobalOptimization.OptimizationProblem","text":"OptimizationProblem{has_penalty, SS, F, G}\n\nAn optimization problem. Contains the objective function and search space.\n\nFields\n\nf::F: The objective function.\ng!::G: The gradient of the objective function.\nss::SS: The search space.\n\n\n\n\n\n","category":"type"},{"location":"lib/public/#GlobalOptimization.OptimizationProblem-Union{Tuple{F}, Tuple{F, AbstractVector{<:Real}, AbstractVector{<:Real}}} where F<:Function","page":"Public API","title":"GlobalOptimization.OptimizationProblem","text":"OptimizationProblem(f, [g], LB, UB)\n\nConstructs an optimization problem with objective function f, optional gradient g, and a ContinuousRectangularSearchSpace defined by LB and UB.\n\nArguments\n\nf::F: The objective function.\nLB::AbstractVector{<:Real}: The lower bounds of the search space.\nUB::AbstractVector{<:Real}: The upper bounds of the search space.\n\nReturns\n\nOptimizationProblem{ContinuousRectangularSearchSpace, F}\n\nExamples\n\njulia> using GlobalOptimization;\njulia> f(x) = sum(x.^2); # Simple sphere function\njulia> LB = [-1.0, 0.0];\njulia> UB = [ 1.0, 2.0];\njulia> prob = OptimizationProblem(f, LB, UB)\nOptimizationProblem{ContinuousRectangularSearchSpace{Float64}, typeof(f)}(f, ContinuousRectangularSearchSpace{Float64}([-1.0, 0.0], [1.0, 2.0], [2.0, 2.0]))\n\n\n\n\n\n","category":"method"},{"location":"lib/public/#GlobalOptimization.OptimizationProblem-Union{Tuple{F}, Tuple{has_penalty}, Tuple{T}, Tuple{F, GlobalOptimization.SearchSpace{T}}} where {T, has_penalty, F<:Function}","page":"Public API","title":"GlobalOptimization.OptimizationProblem","text":"OptimizationProblem{has_penalty}(f::F, [g::G], ss::SS)\n\nConstructs an optimization problem with objective function f, optional gradient g, and search space ss. If has_penalty is specified as true, then the objective function must return a Tuple{T,T} for a given x of type AbstractArray{T}.\n\nArguments\n\nf::F: The objective function.\ng::G: The gradient of the objective function.\nss::SS: The search space.\n\nReturns\n\nOptimizationProblem{SS, F}\n\nExamples\n\njulia> using GlobalOptimization;\njulia> f(x) = sum(x.^2); # Simple sphere function\njulia> LB = [-1.0, 0.0];\njulia> UB = [ 1.0, 2.0];\njulia> ss = ContinuousRectangularSearchSpace(LB, UB);\njulia> prob = OptimizationProblem(f, ss)\nOptimizationProblem{ContinuousRectangularSearchSpace{Float64}, typeof(f)}(f, ContinuousRectangularSearchSpace{Float64}([-1.0, 0.0], [1.0, 2.0], [2.0, 2.0]))\n\n\n\n\n\n","category":"method"},{"location":"lib/public/#GlobalOptimization.OptimizationProblem-Union{Tuple{SS}, Tuple{F}, Tuple{F, SS}} where {F<:Function, SS<:GlobalOptimization.SearchSpace}","page":"Public API","title":"GlobalOptimization.OptimizationProblem","text":"OptimizationProblem(f, [g], ss)\n\nConstructs an optimization problem with objective function f, optimal gradient g, and a search space.\n\nArguments\n\nf::F: The objective function.\ng::G: The gradient of the objective function.\nss::SS: The search space.\n\nReturns\n\nOptimizationProblem{ContinuousRectangularSearchSpace, F}\n\nExamples\n\njulia> using GlobalOptimization;\njulia> f(x) = sum(x.^2); # Simple sphere function\njulia> LB = [-1.0, 0.0];\njulia> UB = [ 1.0, 2.0];\njulia> prob = OptimizationProblem(f, ContinuousRectangularSearchSpace(LB, UB))\nOptimizationProblem{ContinuousRectangularSearchSpace{Float64}, typeof(f)}(f, ContinuousRectangularSearchSpace{Float64}([-1.0, 0.0], [1.0, 2.0], [2.0, 2.0]))\n\n\n\n\n\n","category":"method"},{"location":"lib/public/#Search-Space","page":"Public API","title":"Search Space","text":"","category":"section"},{"location":"lib/public/#GlobalOptimization.ContinuousRectangularSearchSpace","page":"Public API","title":"GlobalOptimization.ContinuousRectangularSearchSpace","text":"ContinuousRectangularSearchSpace{T <: AbstractFloat}\n\nA RectangularSearchSpace formed by a single continuous set.\n\nFields\n\ndimmin::Vector{T}: A vector of minimum values for each dimension.\ndimmax::Vector{T}: A vector of maximum values for each dimension.\ndimdelta::Vector{T}: A vector of the difference between the maximum and minimum values for each dimension.\n\n\n\n\n\n","category":"type"},{"location":"lib/public/#GlobalOptimization.ContinuousRectangularSearchSpace-Union{Tuple{T2}, Tuple{T1}, Tuple{AbstractVector{T1}, AbstractVector{T2}}} where {T1<:Real, T2<:Real}","page":"Public API","title":"GlobalOptimization.ContinuousRectangularSearchSpace","text":"ContinuousRectangularSearchSpace(dimmin::AbstractVector{T}, dimmax::AbstractVector{T})\n\nConstructs a new ContinuousRectangularSearchSpace with minimum values dimmin and maximum values dimmax.\n\nArguments\n\ndimmin::AbstractVector{T}: A vector of minimum values for each dimension.\ndimmax::AbstractVector{T}: A vector of maximum values for each dimension.\n\nReturns\n\nContinuousRectangularSearchSpace{T}\n\nExamples\n\njulia> using GlobalOptimization;\njulia> LB = [-1.0, 0.0];\njulia> UB = [ 1.0, 2.0];\njulia> ss = ContinuousRectangularSearchSpace(LB, UB)\nContinuousRectangularSearchSpace{Float64}([-1.0, 0.0], [1.0, 2.0], [2.0, 2.0])\n\n\n\n\n\n","category":"method"},{"location":"lib/public/#Optimization","page":"Public API","title":"Optimization","text":"","category":"section"},{"location":"lib/public/#GlobalOptimization.optimize!-Tuple{GlobalOptimization.AbstractOptimizer}","page":"Public API","title":"GlobalOptimization.optimize!","text":"optimize!(opt::AbstractOptimizer)\n\nPerform optimization using the optimizer opt. Returns the results of the optimization.\n\nArguments\n\nopt::AbstractOptimizer: The optimizer to use.\n\nReturns\n\nResults: The results of the optimization.\n\n\n\n\n\n","category":"method"},{"location":"lib/public/#Algorithms","page":"Public API","title":"Algorithms","text":"","category":"section"},{"location":"lib/public/#Particle-Swarm-Optimization","page":"Public API","title":"Particle Swarm Optimization","text":"","category":"section"},{"location":"lib/public/#GlobalOptimization.PolyesterPSO-Union{Tuple{GlobalOptimization.AbstractProblem{has_penalty, SS}}, Tuple{has_penalty}, Tuple{SS}, Tuple{T}} where {T<:AbstractFloat, SS<:ContinuousRectangularSearchSpace{T}, has_penalty}","page":"Public API","title":"GlobalOptimization.PolyesterPSO","text":"PolyesterPSO(prob::AbstractOptimizationProblem{SS}; kwargs...)\n\nConstructs a PSO algorithm with the given options that will employ a PolyesterBatchEvaluator to evaluate the objective function each iteration.\n\nArguments\n\nprob::AbstractOptimizationProblem{SS}: The optimization problem to solve.\n\nKeyword Arguments\n\nnum_particles::Int = 100: The number of particles to use.\ninitial_bounds::Union{Nothing,ContinuousRectangularSearchSpace} = nothing: The initial bounds to use when initializing particle positions.\nmax_iterations::Int = 1000: The maximum number of iterations to perform.\nfunction_tolerence::AbstractFloat = 1e-6: The function value tolerence to use for stopping criteria.\nmax_stall_time::Real = Inf: The maximum amount of time to allow for stall time.\nmax_stall_iterations::Int = 25: The maximum number of stall iterations to allow.\ninertia_range::Tuple{AbstractFloat,AbstractFloat} = (0.1, 1.0): The range of allowable inertia weights.\nminimum_neighborhood_fraction::AbstractFloat = 0.25: The minimum neighborhood fraction to use.\nself_adjustment_weight::Real = 1.49: The self adjustment weight to use.\nsocial_adjustment_weight::Real = 1.49: The social adjustment weight to use.\ndisplay::Bool = false: Whether or not to display the status of the algorithm.\ndisplay_interval::Int = 1: The display interval to use.\nfunction_value_check::Bool = true: Whether or not to check for bad function values (Inf or NaN).\nmax_time::Real = 60.0: The maximum amount of time to allow for optimization.\n\nReturns\n\nPSO: The PSO algorithm.\n\n\n\n\n\n","category":"method"},{"location":"lib/public/#GlobalOptimization.SerialPSO-Union{Tuple{GlobalOptimization.AbstractProblem{has_penalty, SS}}, Tuple{has_penalty}, Tuple{SS}, Tuple{T}} where {T<:AbstractFloat, SS<:ContinuousRectangularSearchSpace{T}, has_penalty}","page":"Public API","title":"GlobalOptimization.SerialPSO","text":"SerialPSO(prob::AbstractProblem{has_penalty,SS}; kwargs...)\n\nConstructs a PSO algorithm with the given options that will employ a SerialBatchEvaluator to evaluate the objective function each iteration.\n\nArguments\n\nprob::AbstractProblem{has_penalty,SS}: The problem to solve.\n\nKeyword Arguments\n\nnum_particles::Int = 100: The number of particles to use.\ninitial_bounds::Union{Nothing,ContinuousRectangularSearchSpace} = nothing: The initial bounds to use when initializing particle positions.\nmax_iterations::Int = 1000: The maximum number of iterations to perform.\nfunction_tolerence::AbstractFloat = 1e-6: The function value tolerence to use for stopping criteria.\nmax_stall_time::Real = Inf: The maximum amount of time to allow for stall time.\nmax_stall_iterations::Int = 25: The maximum number of stall iterations to allow.\ninertia_range::Tuple{AbstractFloat,AbstractFloat} = (0.1, 1.0): The range of allowable inertia weights.\nminimum_neighborhood_fraction::AbstractFloat = 0.25: The minimum neighborhood fraction to use.\nself_adjustment_weight::Real = 1.49: The self adjustment weight to use.\nsocial_adjustment_weight::Real = 1.49: The social adjustment weight to use.\ndisplay::Bool = false: Whether or not to display the status of the algorithm.\ndisplay_interval::Int = 1: The display interval to use.\nfunction_value_check::Bool = true: Whether or not to check for bad function values (Inf or NaN).\nmax_time::Real = 60.0: The maximum amount of time to allow for optimization.\n\nReturns\n\nPSO: The PSO algorithm.\n\n\n\n\n\n","category":"method"},{"location":"lib/public/#GlobalOptimization.ThreadedPSO-Union{Tuple{GlobalOptimization.AbstractProblem{has_penalty, SS}}, Tuple{has_penalty}, Tuple{SS}, Tuple{T}} where {T<:AbstractFloat, SS<:ContinuousRectangularSearchSpace{T}, has_penalty}","page":"Public API","title":"GlobalOptimization.ThreadedPSO","text":"ThreadedPSO(prob::AbstractOptimizationProblem{SS}; kwargs...)\n\nConstructs a PSO algorithm with the given options that will employ a ThreadedBatchEvaluator to evaluate the objective function each iteration.\n\nArguments\n\nprob::AbstractOptimizationProblem{SS}: The optimization problem to solve.\n\nKeyword Arguments\n\nnum_particles::Int = 100: The number of particles to use.\ninitial_bounds::Union{Nothing,ContinuousRectangularSearchSpace} = nothing: The initial bounds to use when initializing particle positions.\nmax_iterations::Int = 1000: The maximum number of iterations to perform.\nfunction_tolerence::AbstractFloat = 1e-6: The function value tolerence to use for stopping criteria.\nmax_stall_time::Real = Inf: The maximum amount of time to allow for stall time.\nmax_stall_iterations::Int = 25: The maximum number of stall iterations to allow.\ninertia_range::Tuple{AbstractFloat,AbstractFloat} = (0.1, 1.0): The range of allowable inertia weights.\nminimum_neighborhood_fraction::AbstractFloat = 0.25: The minimum neighborhood fraction to use.\nself_adjustment_weight::Real = 1.49: The self adjustment weight to use.\nsocial_adjustment_weight::Real = 1.49: The social adjustment weight to use.\ndisplay::Bool = false: Whether or not to display the status of the algorithm.\ndisplay_interval::Int = 1: The display interval to use.\nfunction_value_check::Bool = true: Whether or not to check for bad function values (Inf or NaN).\nmax_time::Real = 60.0: The maximum amount of time to allow for optimization.\n\nReturns\n\nPSO: The PSO algorithm.\n\n\n\n\n\n","category":"method"},{"location":"lib/public/#Differential-Evolution","page":"Public API","title":"Differential Evolution","text":"","category":"section"},{"location":"lib/public/#GlobalOptimization.PolyesterDE-Union{Tuple{GlobalOptimization.AbstractProblem{has_penalty, SS}}, Tuple{has_penalty}, Tuple{SS}, Tuple{T}, Tuple{CP}, Tuple{MP}} where {MP<:GlobalOptimization.AbstractMutationParameters, CP<:GlobalOptimization.AbstractCrossoverParameters, T<:AbstractFloat, SS<:ContinuousRectangularSearchSpace{T}, has_penalty}","page":"Public API","title":"GlobalOptimization.PolyesterDE","text":"PolyesterDE(prob::AbstractProblem{has_penalty,SS}; kwargs...)\n\nConstruct a serial Differential Evolution (DE) algorithm with the given options that will employ a PolyesterBatchEvaluator to evaluate the objective function each iteration.\n\nArguments\n\nprob::AbstractProblem{has_penalty,SS}: The problem to solve.\n\nKeyword Arguments\n\nnum_candidates::Integer=100: The number of candidates in the population.\nmutation_params::MP=SelfMutationParameters(Rand1()): The mutation strategy parameters.\ncrossover_params::CP=BinomialCrossoverParameters(0.6): The crossover strategy parameters.\ninitial_bounds::Union{Nothing,ContinuousRectangularSearchSpace}=nothing: The initial bounds for the search space.\nmax_iterations::Integer=1000: The maximum number of iterations.\nmax_time::Real=60.0: The maximum time to run the algorithm.\nfunction_tolerance::Real=1e-6: The function tolerance for the stall condition.\nmax_stall_time::Real=60.0: The maximum stall time for the stall condition.\nmax_stall_iterations::Integer=100: The maximum number of stall iterations for the stall condition.\nmin_cost::Real=-Inf: The minimum cost for the algorithm to stop.\nfunction_value_check::Bool=true: Whether to check the function value.\ndisplay::Bool=true: Whether to display the algorithm status.\ndisplay_interval::Integer=1: The interval at which to display the algorithm status.\n\n\n\n\n\n","category":"method"},{"location":"lib/public/#GlobalOptimization.SerialDE-Union{Tuple{GlobalOptimization.AbstractProblem{has_penalty, SS}}, Tuple{has_penalty}, Tuple{SS}, Tuple{T}, Tuple{CP}, Tuple{MP}} where {MP<:GlobalOptimization.AbstractMutationParameters, CP<:GlobalOptimization.AbstractCrossoverParameters, T<:AbstractFloat, SS<:ContinuousRectangularSearchSpace{T}, has_penalty}","page":"Public API","title":"GlobalOptimization.SerialDE","text":"SerialDE(prob::AbstractProblem{has_penalty,SS}; kwargs...)\n\nConstruct a serial Differential Evolution (DE) algorithm with the given options that will employ a SerialBatchEvaluator to evaluate the objective function each iteration.\n\nArguments\n\nprob::AbstractProblem{has_penalty,SS}: The problem to solve.\n\nKeyword Arguments\n\nnum_candidates::Integer=100: The number of candidates in the population.\nmutation_params::MP=SelfMutationParameters(Rand1()): The mutation strategy parameters.\ncrossover_params::CP=BinomialCrossoverParameters(0.6): The crossover strategy parameters.\ninitial_bounds::Union{Nothing,ContinuousRectangularSearchSpace}=nothing: The initial bounds for the search space.\nmax_iterations::Integer=1000: The maximum number of iterations.\nmax_time::Real=60.0: The maximum time to run the algorithm.\nfunction_tolerance::Real=1e-6: The function tolerance for the stall condition.\nmax_stall_time::Real=60.0: The maximum stall time for the stall condition.\nmax_stall_iterations::Integer=100: The maximum number of stall iterations for the stall condition.\nmin_cost::Real=-Inf: The minimum cost for the algorithm to stop.\nfunction_value_check::Bool=true: Whether to check the function value.\ndisplay::Bool=true: Whether to display the algorithm status.\ndisplay_interval::Integer=1: The interval at which to display the algorithm status.\n\n\n\n\n\n","category":"method"},{"location":"lib/public/#GlobalOptimization.ThreadedDE-Union{Tuple{GlobalOptimization.AbstractProblem{has_penalty, SS}}, Tuple{has_penalty}, Tuple{SS}, Tuple{T}, Tuple{CP}, Tuple{MP}} where {MP<:GlobalOptimization.AbstractMutationParameters, CP<:GlobalOptimization.AbstractCrossoverParameters, T<:AbstractFloat, SS<:ContinuousRectangularSearchSpace{T}, has_penalty}","page":"Public API","title":"GlobalOptimization.ThreadedDE","text":"ThreadedDE(prob::AbstractProblem{has_penalty,SS}; kwargs...)\n\nConstruct a serial Differential Evolution (DE) algorithm with the given options that will employ a ThreadedBatchEvaluator to evaluate the objective function each iteration.\n\nArguments\n\nprob::AbstractProblem{has_penalty,SS}: The problem to solve.\n\nKeyword Arguments\n\nnum_candidates::Integer=100: The number of candidates in the population.\nmutation_params::MP=SelfMutationParameters(Rand1()): The mutation strategy parameters.\ncrossover_params::CP=BinomialCrossoverParameters(0.6): The crossover strategy parameters.\ninitial_bounds::Union{Nothing,ContinuousRectangularSearchSpace}=nothing: The initial bounds for the search space.\nmax_iterations::Integer=1000: The maximum number of iterations.\nmax_time::Real=60.0: The maximum time to run the algorithm.\nfunction_tolerance::Real=1e-6: The function tolerance for the stall condition.\nmax_stall_time::Real=60.0: The maximum stall time for the stall condition.\nmax_stall_iterations::Integer=100: The maximum number of stall iterations for the stall condition.\nmin_cost::Real=-Inf: The minimum cost for the algorithm to stop.\nfunction_value_check::Bool=true: Whether to check the function value.\ndisplay::Bool=true: Whether to display the algorithm status.\ndisplay_interval::Integer=1: The interval at which to display the algorithm status.\n\n\n\n\n\n","category":"method"},{"location":"lib/public/#Mutation-Parameters","page":"Public API","title":"Mutation Parameters","text":"","category":"section"},{"location":"lib/public/#GlobalOptimization.MutationParameters","page":"Public API","title":"GlobalOptimization.MutationParameters","text":"MutationParameters{\n    AS<:AbstractAdaptationStrategy,\n    MS<:AbstractMutationStrategy,\n    S<:AbstractSelector,\n    D,\n}\n\nThe parameters for a DE mutation strategy that applies to all current and future candidates in the population.\n\nFields\n\nF1::Float64: The F₁ weight in the unified mutation strategy.\nF2::Float64: The F₂ weight in the unified mutation strategy.\nF3::Float64: The F₃ weight in the unified mutation strategy.\nF4::Float64: The F₄ weight in the unified mutation strategy.\nsel<:AbstractSelector: The selector used to select the candidates considered in   mutation.\ndist<:Distribution{Univariate,Continuous}: The distribution used to adapt the mutation   parameters. Note that this should generally be a distribution from Distributions.jl, but   the only strict requirement is that rand(dist) returns a floating point value.\n\n\n\n\n\n","category":"type"},{"location":"lib/public/#GlobalOptimization.MutationParameters-NTuple{4, Any}","page":"Public API","title":"GlobalOptimization.MutationParameters","text":"MutationParameters(F1, F2, F3, F4; sel=SimpleSelector())\n\nCreates a MutationParameters object with the specified (constant) mutation parameters. These constant mutation parameters are used for all candidates in the population and define a unified mutation strategy as defined in Ji Qiang and Chad Mitchell \"A Unified Differential Evolution Algorithm for Global Optimization,\" 2014, https://www.osti.gov/servlets/purl/1163659\n\nArguments\n\nF1::Float64: The F₁ weight in the unified mutation strategy.\nF2::Float64: The F₂ weight in the unified mutation strategy.\nF3::Float64: The F₃ weight in the unified mutation strategy.\nF4::Float64: The F₄ weight in the unified mutation strategy.\n\nKeyword Arguments\n\nsel::AbstractSelector: The selector used to select the candidates considered in   mutation. Defaults to SimpleSelector().\n\n\n\n\n\n","category":"method"},{"location":"lib/public/#GlobalOptimization.MutationParameters-Tuple{GlobalOptimization.AbstractMutationStrategy}","page":"Public API","title":"GlobalOptimization.MutationParameters","text":"MutationParameters(\n    strategy::MS;\n    dist=default_mutation_dist,\n    sel=SimpleSelector(),\n)\n\nCreates a MutationParameters object with the specified mutation strategy with mutation parameter random adaptation. The mutation parameters are adaptively sampled from the provided dist, clamped to the range (0, 1].\n\nArguments\n\nstrategy::MS: The mutation strategy to use. This should be one of the mutation   strategies defined in this module (e.g., Rand1, Best2, etc.).\n\nKeyword Arguments\n\ndist::Distribution{Univariate,Continuous}: The distribution used to adapt the   mutation parameters each iteration. Note that this should generally be a   distribution from Distributions.jl, but the only strict requirement is that   rand(dist) returns a floating point value. Defaults to   GlobalOptimization.default_mutation_dist, which is a mixture model comprised of   two Cauchy distributions, with probability density given by:\nf_mix(x mu sigma) = 05 f(xmu_1sigma_1) + 05 f(xmu_2sigma_2).\nwhere mu = 065 10 and sigma = 01 01.\nsel::AbstractSelector: The selector used to select the candidates considered in   mutation. Defaults to SimpleSelector().\n\n\n\n\n\n","category":"method"},{"location":"lib/public/#GlobalOptimization.SelfMutationParameters","page":"Public API","title":"GlobalOptimization.SelfMutationParameters","text":"SelfMutationParameters{\n    AS<:AbstractAdaptationStrategy,\n    MS<:AbstractMutationStrategy,\n    S<:AbstractSelector,\n    D,\n}\n\nThe parameters for a DE mutation strategy that applies a mutation strategy with unique parameters for each candidate in the population.\n\nFields\n\nFs::Vector{SVector{4,Float64}}: The mutation parameters for each candidate in the   population. Each element of the vector is an SVector{4} containing the F₁, F₂, F₃, and   F₄ weights for the unified mutation strategy.\nsel<:AbstractSelector: The selector used to select the candidates considered in mutation.\ndist<:Distribution{Univariate,Continuous}: The distribution used to adapt the mutation   parameters. Note that this should generally be a distribution from Distributions.jl, but   the only strict requirement is that rand(dist) returns a floating point value.\n\n\n\n\n\n","category":"type"},{"location":"lib/public/#GlobalOptimization.SelfMutationParameters-Tuple{GlobalOptimization.AbstractMutationStrategy}","page":"Public API","title":"GlobalOptimization.SelfMutationParameters","text":"SelfMutationParameters(\n    strategy::MS;\n    dist=default_mutation_dist,\n    sel=SimpleSelector(),\n)\n\nCreates a SelfMutationParameters object with the specified mutation strategy and mutation parameter random adaptation. The mutation parameters are adaptively sampled from the provided dist, clamped to the range (0, 1].\n\nArguments\n\nstrategy::MS: The mutation strategy to use. This should be one of the mutation   strategies defined in this module (e.g., Rand1, Best2, etc.).\n\nKeyword Arguments\n\ndist::Distribution{Univariate,Continuous}: The distribution used to adapt the   mutation parameters each iteration. Note that this should generally be a   distribution from Distributions.jl, but the only strict requirement is that   rand(dist) returns a floating point value. Defaults to   GlobalOptimization.default_mutation_dist, which is a mixture model comprised of   two Cauchy distributions, with probability density given by:\nf_mix(x mu sigma) = 05 f(xmu_1sigma_1) + 05 f(xmu_2sigma_2).\nwhere mu = 065 10 and sigma = 01 01.\nsel::AbstractSelector: The selector used to select the candidates considered in   mutation. Defaults to SimpleSelector().\n\n\n\n\n\n","category":"method"},{"location":"lib/public/#GlobalOptimization.Rand1","page":"Public API","title":"GlobalOptimization.Rand1","text":"Rand1\n\nThe DE/rand/1 mutation strategy.\n\n\n\n\n\n","category":"type"},{"location":"lib/public/#GlobalOptimization.Rand2","page":"Public API","title":"GlobalOptimization.Rand2","text":"Rand2\n\nThe DE/rand/2 mutation strategy.\n\n\n\n\n\n","category":"type"},{"location":"lib/public/#GlobalOptimization.Best1","page":"Public API","title":"GlobalOptimization.Best1","text":"Best1\n\nThe DE/best/1 mutation strategy.\n\n\n\n\n\n","category":"type"},{"location":"lib/public/#GlobalOptimization.Best2","page":"Public API","title":"GlobalOptimization.Best2","text":"Best2\n\nThe DE/best/2 mutation strategy.\n\n\n\n\n\n","category":"type"},{"location":"lib/public/#GlobalOptimization.CurrentToBest1","page":"Public API","title":"GlobalOptimization.CurrentToBest1","text":"CurrentToBest1\n\nThe DE/current-to-best/1 mutation strategy.\n\n\n\n\n\n","category":"type"},{"location":"lib/public/#GlobalOptimization.CurrentToBest2","page":"Public API","title":"GlobalOptimization.CurrentToBest2","text":"CurrentToBest2\n\nThe DE/current-to-best/2 mutation strategy.\n\n\n\n\n\n","category":"type"},{"location":"lib/public/#GlobalOptimization.CurrentToRand1","page":"Public API","title":"GlobalOptimization.CurrentToRand1","text":"CurrentToRand1\n\nThe DE/current-to-rand/1 mutation strategy.\n\n\n\n\n\n","category":"type"},{"location":"lib/public/#GlobalOptimization.CurrentToRand2","page":"Public API","title":"GlobalOptimization.CurrentToRand2","text":"CurrentToRand2\n\nThe DE/current-to-rand/2 mutation strategy.\n\n\n\n\n\n","category":"type"},{"location":"lib/public/#GlobalOptimization.RandToBest1","page":"Public API","title":"GlobalOptimization.RandToBest1","text":"RandToBest1\n\nThe DE/rand-to-best/1 mutation strategy.\n\n\n\n\n\n","category":"type"},{"location":"lib/public/#GlobalOptimization.RandToBest2","page":"Public API","title":"GlobalOptimization.RandToBest2","text":"RandToBest2\n\nThe DE/rand-to-best/2 mutation strategy.\n\n\n\n\n\n","category":"type"},{"location":"lib/public/#GlobalOptimization.Unified","page":"Public API","title":"GlobalOptimization.Unified","text":"Unified\n\nThe unified DE mutation strategy proposed by Ji Qiang and Chad Mitchell in \"A Unified Differential Evolution Algorithm for Global Optimization,\" 2014, https://www.osti.gov/servlets/purl/1163659\n\n\n\n\n\n","category":"type"},{"location":"lib/public/#GlobalOptimization.SimpleSelector","page":"Public API","title":"GlobalOptimization.SimpleSelector","text":"SimpleSelector\n\nA selector that simply selects all candidates in the population.\n\n\n\n\n\n","category":"type"},{"location":"lib/public/#GlobalOptimization.RadiusLimitedSelector","page":"Public API","title":"GlobalOptimization.RadiusLimitedSelector","text":"RadiusLimitedSelector\n\nA selector that selects candidates within a given radius of the target candidate.\n\nFor example, for population size of 10 and a radius of 2, the following will be selected for the given target indices:\n\ntarget = 5 will select [3, 4, 5, 6, 7]\n\ntarget = 1 will select [9, 10, 1, 2, 3]\n\ntarget = 9 will select [7, 8, 9, 10, 1]\n\n\n\n\n\n","category":"type"},{"location":"lib/public/#DE-Crossover-Strategies","page":"Public API","title":"DE Crossover Strategies","text":"","category":"section"},{"location":"#GlobalOptimization","page":"Home","title":"GlobalOptimization","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Currently, GlobalOptimization provides Particle Swarm Optimization (PSO) and several variants of Differential Evolution (DE) as the only global optimization algorithms supported. Monotonic Basin Hopping (MBH) is in the works.","category":"page"},{"location":"#Simple-PSO-Example","page":"Home","title":"Simple PSO Example","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Let's use PSO to find the minimum to the non-convex Ackley function given by","category":"page"},{"location":"","page":"Home","title":"Home","text":"J(mathbfx) = -a expleft(-bsqrtfrac1dsum_i=1^d x_i^2right) - expleft(frac1dsum_i=1^d cos (cx_i)right) + a + exp(1)","category":"page"},{"location":"","page":"Home","title":"Home","text":"where a = 20, b = 02, c = 2pi, and d is the length of the decision vector mathbfx, subject to the constraint that -32768 leq x_i leq 32768 hspace1mm forall hspace1mm x_i hspace1mm in hspace1mm mathbfx.","category":"page"},{"location":"","page":"Home","title":"Home","text":"To begin, we'll first define an Ackley function in Julia as follows:","category":"page"},{"location":"","page":"Home","title":"Home","text":"function ackley(x)\n    a = 20\n    b = 0.2\n    c = 2*π\n    d = length(x)\n\n    sum1 = 0.0\n    sum2 = 0.0\n    for val in x\n        sum1 += val^2\n        sum2 += cos(c*val)\n    end\n    return -a*exp(-b*sqrt(sum1/d)) - exp(sum2/d) + a + exp(1)\nend\nnothing # hide","category":"page"},{"location":"","page":"Home","title":"Home","text":"Next, we'll define the OptimizationProblem by providing its constructor our new ackley function and bounds that define the search space. Then, we'll instantiate a StaticPSO (an implementation of the PSO algorithm that does not use parallel computing to evaluate the cost function) to perform the optimization!","category":"page"},{"location":"","page":"Home","title":"Home","text":"using GlobalOptimization\n\nN   = 10 # The number of decision variables\nLB  = [-32.768 for _ in 1:10] # The lower bounds\nUB  = [ 32.768 for _ in 1:10] # The upper bounds\n\n# Construct the optimization problem\nop  = OptimizationProblem(ackley, LB, UB)\n\n# Instantiate SerialPSO instance\npso = SerialPSO(op)\n\n# Perform optimization with pso\nres = optimize!(pso)\nnothing # hide","category":"page"},{"location":"","page":"Home","title":"Home","text":"Finally, we can get the final optimal decision vector with","category":"page"},{"location":"","page":"Home","title":"Home","text":"best_candidate = res.xbest","category":"page"},{"location":"","page":"Home","title":"Home","text":"and the fitness of the final optimal decision vector with","category":"page"},{"location":"","page":"Home","title":"Home","text":"best_candidate_fitness = res.fbest","category":"page"},{"location":"#Index","page":"Home","title":"Index","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"","category":"page"}]
}
