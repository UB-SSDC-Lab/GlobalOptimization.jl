<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Public API · GlobalOptimization.jl</title><meta name="title" content="Public API · GlobalOptimization.jl"/><meta property="og:title" content="Public API · GlobalOptimization.jl"/><meta property="twitter:title" content="Public API · GlobalOptimization.jl"/><meta name="description" content="Documentation for GlobalOptimization.jl."/><meta property="og:description" content="Documentation for GlobalOptimization.jl."/><meta property="twitter:description" content="Documentation for GlobalOptimization.jl."/><meta property="og:url" content="https://UB-SSDC-Lab.github.io/GlobalOptimization.jl/lib/public/"/><meta property="twitter:url" content="https://UB-SSDC-Lab.github.io/GlobalOptimization.jl/lib/public/"/><link rel="canonical" href="https://UB-SSDC-Lab.github.io/GlobalOptimization.jl/lib/public/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">GlobalOptimization.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Reference</span><ul><li class="is-active"><a class="tocitem" href>Public API</a><ul class="internal"><li><a class="tocitem" href="#Contents"><span>Contents</span></a></li><li><a class="tocitem" href="#Problems"><span>Problems</span></a></li><li><a class="tocitem" href="#Search-Space"><span>Search Space</span></a></li><li><a class="tocitem" href="#Optimization"><span>Optimization</span></a></li><li><a class="tocitem" href="#Population-Initialization"><span>Population Initialization</span></a></li><li><a class="tocitem" href="#Function-Evaluation-Methods"><span>Function Evaluation Methods</span></a></li><li><a class="tocitem" href="#Algorithms"><span>Algorithms</span></a></li><li><a class="tocitem" href="#Trace-Options"><span>Trace Options</span></a></li><li><a class="tocitem" href="#Index"><span>Index</span></a></li></ul></li></ul></li><li><span class="tocitem">Developers</span><ul><li><a class="tocitem" href="../../dev/contributing/">Contributing</a></li><li><input class="collapse-toggle" id="menuitem-3-2" type="checkbox"/><label class="tocitem" for="menuitem-3-2"><span class="docs-label">Internals</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../internal/temp/">Internals</a></li></ul></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Reference</a></li><li class="is-active"><a href>Public API</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Public API</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/main/docs/src/lib/public.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Public-API-Documentation"><a class="docs-heading-anchor" href="#Public-API-Documentation">Public API Documentation</a><a id="Public-API-Documentation-1"></a><a class="docs-heading-anchor-permalink" href="#Public-API-Documentation" title="Permalink"></a></h1><p>Documentation for GlobalOptimization&#39;s public interface.</p><h2 id="Contents"><a class="docs-heading-anchor" href="#Contents">Contents</a><a id="Contents-1"></a><a class="docs-heading-anchor-permalink" href="#Contents" title="Permalink"></a></h2><ul><li><a href="#Contents">Contents</a></li><li><a href="#Problems">Problems</a></li><li><a href="#Search-Space">Search Space</a></li><li><a href="#Optimization">Optimization</a></li><li><a href="#Population-Initialization">Population Initialization</a></li><li><a href="#Function-Evaluation-Methods">Function Evaluation Methods</a></li><li><a href="#Algorithms">Algorithms</a></li><li class="no-marker"><ul><li><a href="#Particle-Swarm-Optimization">Particle Swarm Optimization</a></li><li><a href="#Differential-Evolution">Differential Evolution</a></li><li><a href="#Monotonic-Basin-Hopping">Monotonic Basin Hopping</a></li></ul></li><li><a href="#Trace-Options">Trace Options</a></li><li><a href="#Index">Index</a></li></ul><h2 id="Problems"><a class="docs-heading-anchor" href="#Problems">Problems</a><a id="Problems-1"></a><a class="docs-heading-anchor-permalink" href="#Problems" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.NonlinearLeastSquaresProblem" href="#GlobalOptimization.NonlinearLeastSquaresProblem"><code>GlobalOptimization.NonlinearLeastSquaresProblem</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">NonlinearLeastSquaresProblem{has_penalty, SS, F, G}</code></pre><p>A nonlinear least squares problem. Contains the nonlinear equations and search space.</p><p><strong>Fields</strong></p><ul><li><code>f::F</code>: The nonlinear equations.</li><li><code>g!::G</code>: The jacobian of the nonlinear equations.</li><li><code>ss::SS</code>: The search space.</li><li><code>n::Int</code>: The number of residuals.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/Problem.jl#L302-L312">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.NonlinearLeastSquaresProblem-Union{Tuple{F}, Tuple{F, AbstractVector{&lt;:Real}, AbstractVector{&lt;:Real}, Int64}} where F&lt;:Function" href="#GlobalOptimization.NonlinearLeastSquaresProblem-Union{Tuple{F}, Tuple{F, AbstractVector{&lt;:Real}, AbstractVector{&lt;:Real}, Int64}} where F&lt;:Function"><code>GlobalOptimization.NonlinearLeastSquaresProblem</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">NonlinearLeastSquaresProblem(f, [g], LB, UB)</code></pre><p>Constructs a nonlinear least squares problem with nonlinear function <code>f</code>, optional Jacobian <code>g</code>, and a search space.</p><p><strong>Arguments</strong></p><ul><li><code>f::F</code>: The nonlinear function.</li><li><code>g::G</code>: The Jacobian of the nonlinear function.</li><li><code>LB::AbstractVector{&lt;:Real}</code>: The lower bounds of the search space.</li><li><code>UB::AbstractVector{&lt;:Real}</code>: The upper bounds of the search space.</li></ul><p><strong>Returns</strong></p><ul><li><code>NonlinearLeastSquaresProblem{has_penalty, ContinuousRectangularSearchSpace, F, G}</code></li></ul><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using GlobalOptimization;
julia&gt; f(x) = [x[1] - x[3], x[2] - x[3]]
julia&gt; LB = [-5.0, -5.0, -5.0];
julia&gt; UB = [ 5.0, 5.0, 5.0];
julia&gt; prob = NonlinearLeastSquaresProblem(f, ss, LB, UB, 2)
NonlinearLeastSquaresProblem{Val{false}(), ContinuousRectangularSearchSpace{Float64}, typeof(f), Nothing}(f, nothing, ContinuousRectangularSearchSpace{Float64}([-5.0, -5.0, -5.0], [5.0, 5.0, 5.0], [10.0, 10.0, 10.0]), 2)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/Problem.jl#L410-L433">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.NonlinearLeastSquaresProblem-Union{Tuple{F}, Tuple{has_penalty}, Tuple{T}, Tuple{F, GlobalOptimization.SearchSpace{T}, Int64}} where {T, has_penalty, F&lt;:Function}" href="#GlobalOptimization.NonlinearLeastSquaresProblem-Union{Tuple{F}, Tuple{has_penalty}, Tuple{T}, Tuple{F, GlobalOptimization.SearchSpace{T}, Int64}} where {T, has_penalty, F&lt;:Function}"><code>GlobalOptimization.NonlinearLeastSquaresProblem</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">NonlinearLeastSquaresProblem{has_penalty}(f::F, [g::G], ss::SS, num_resid::Int)</code></pre><p>Constructs a nonlinear least squares problem with nonlinear functions <code>f</code>, optional jacobian <code>g</code>, and search space <code>ss</code>. If has_penalty is specified as true, then the nonlinear function must return a Tuple{AbstractArray{T},T} for a given x of type AbstractArray{T}.</p><p><strong>Arguments</strong></p><ul><li><code>f::F</code>: The nonlinear function.</li><li><code>g::G</code>: The Jacobian of the nonlinear function.</li><li><code>ss::SS</code>: The search space.</li><li><code>num_resid::Int</code>: The number of residuals.</li></ul><p><strong>Returns</strong></p><ul><li><code>NonlinearLeastSquaresProblem{has_penalty, SS, F, G}</code></li></ul><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using GlobalOptimization;
julia&gt; f(x) = [x[1] - x[3], x[2] - x[3]]
julia&gt; LB = [-5.0, -5.0, -5.0];
julia&gt; UB = [ 5.0, 5.0, 5.0];
julia&gt; ss = ContinuousRectangularSearchSpace(LB, UB);
julia&gt; prob = NonlinearLeastSquaresProblem(f, ss, 2)
NonlinearLeastSquaresProblem{Val{false}(), ContinuousRectangularSearchSpace{Float64}, typeof(f), Nothing}(f, nothing, ContinuousRectangularSearchSpace{Float64}([-5.0, -5.0, -5.0], [5.0, 5.0, 5.0], [10.0, 10.0, 10.0]), 2)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/Problem.jl#L322-L348">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.NonlinearLeastSquaresProblem-Union{Tuple{SS}, Tuple{F}, Tuple{F, SS, Int64}} where {F&lt;:Function, SS&lt;:GlobalOptimization.SearchSpace}" href="#GlobalOptimization.NonlinearLeastSquaresProblem-Union{Tuple{SS}, Tuple{F}, Tuple{F, SS, Int64}} where {F&lt;:Function, SS&lt;:GlobalOptimization.SearchSpace}"><code>GlobalOptimization.NonlinearLeastSquaresProblem</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">NonlinearLeastSquaresProblem(f, [g], ss)</code></pre><p>Constructs a nonlinear least squares problem with nonlinear function <code>f</code>, optional Jacobian <code>g</code>, and a search space.</p><p><strong>Arguments</strong></p><ul><li><code>f::F</code>: The nonlinear function.</li><li><code>g::G</code>: The Jacobian of the nonlinear function.</li><li><code>ss::SS</code>: The search space.</li></ul><p><strong>Returns</strong></p><ul><li><code>NonlinearLeastSquaresProblem{has_penalty, ContinuousRectangularSearchSpace, F, G}</code></li></ul><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using GlobalOptimization;
julia&gt; f(x) = [x[1] - x[3], x[2] - x[3]]
julia&gt; LB = [-5.0, -5.0, -5.0];
julia&gt; UB = [ 5.0, 5.0, 5.0];
julia&gt; ss = ContinuousRectangularSearchSpace(LB, UB);
julia&gt; prob = NonlinearLeastSquaresProblem(f, ss, 2)
NonlinearLeastSquaresProblem{Val{false}(), ContinuousRectangularSearchSpace{Float64}, typeof(f), Nothing}(f, nothing, ContinuousRectangularSearchSpace{Float64}([-5.0, -5.0, -5.0], [5.0, 5.0, 5.0], [10.0, 10.0, 10.0]), 2)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/Problem.jl#L373-L396">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.NonlinearProblem" href="#GlobalOptimization.NonlinearProblem"><code>GlobalOptimization.NonlinearProblem</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">NonlinearProblem{has_penalty, SS, F, G}</code></pre><p>A nonlinear problem. Contains the nonlinear equations and search space.</p><p><strong>Fields</strong></p><ul><li><code>f::F</code>: The nonlinear equations.</li><li><code>g!::G</code>: The jacobian of the nonlinear equations.</li><li><code>ss::SS</code>: The search space.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/Problem.jl#L163-L172">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.NonlinearProblem-Union{Tuple{F}, Tuple{F, AbstractVector{&lt;:Real}, AbstractVector{&lt;:Real}}} where F&lt;:Function" href="#GlobalOptimization.NonlinearProblem-Union{Tuple{F}, Tuple{F, AbstractVector{&lt;:Real}, AbstractVector{&lt;:Real}}} where F&lt;:Function"><code>GlobalOptimization.NonlinearProblem</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">NonlinearProblem(f, [g], LB, UB)</code></pre><p>Constructs a nonlinear problem with nonlinear function <code>f</code>, optional Jacobian <code>g</code>, and a continuous rectangular search space defined by the bounds LB and UB.</p><p><strong>Arguments</strong></p><ul><li><code>f::F</code>: The nonlinear function.</li><li><code>g::G</code>: The Jacobian of the nonlinear function.</li><li><code>LB::AbstractVector{&lt;:Real}</code>: The lower bounds of the search space.</li><li><code>UB::AbstractVector{&lt;:Real}</code>: The upper bounds of the search space.</li></ul><p><strong>Returns</strong></p><ul><li><code>NonlinearProblem{has_penalty, ContinuousRectangularSearchSpace, F, G}</code></li></ul><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using GlobalOptimization;
julia&gt; f(x) = [x[1] - 2.0, x[2] - 2.0]
julia&gt; LB = [-5.0, -5.0];
julia&gt; UB = [ 5.0, 5.0];
julia&gt; prob = NonlinearProblem(f, LB, UB)
NonlinearProblem{Val{false}(), ContinuousRectangularSearchSpace{Float64}, typeof(f), Nothing}(f, nothing, ContinuousRectangularSearchSpace{Float64}([-5.0, -5.0], [5.0, 5.0], [10.0, 10.0]))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/Problem.jl#L264-L288">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.NonlinearProblem-Union{Tuple{F}, Tuple{has_penalty}, Tuple{T}, Tuple{F, GlobalOptimization.SearchSpace{T}}} where {T, has_penalty, F&lt;:Function}" href="#GlobalOptimization.NonlinearProblem-Union{Tuple{F}, Tuple{has_penalty}, Tuple{T}, Tuple{F, GlobalOptimization.SearchSpace{T}}} where {T, has_penalty, F&lt;:Function}"><code>GlobalOptimization.NonlinearProblem</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">NonlinearProblem{has_penalty}(f::F, [g::G], ss::SS)</code></pre><p>Constructs a nonlinear problem with nonlinear functions <code>f</code>, optional jacobian <code>g</code>, and search space <code>ss</code>. If has_penalty is specified as true, then the nonlinear function must return a Tuple{AbstractArray{T},T} for a given x of type AbstractArray{T}.</p><p><strong>Arguments</strong></p><ul><li><code>f::F</code>: The nonlinear function.</li><li><code>g::G</code>: The Jacobian of the nonlinear function.</li><li><code>ss::SS</code>: The search space.</li></ul><p><strong>Returns</strong></p><ul><li><code>NonlinearProblem{has_penalty, SS, F, G}</code></li></ul><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using GlobalOptimization;
julia&gt; f(x) = [x[1] - 2.0, x[2] - 2.0]
julia&gt; LB = [-5.0, -5.0];
julia&gt; UB = [ 5.0, 5.0];
julia&gt; ss = ContinuousRectangularSearchSpace(LB, UB);
julia&gt; prob = NonlinearProblem(f, ss)
NonlinearProblem{Val{false}(), ContinuousRectangularSearchSpace{Float64}, typeof(f), Nothing}(f, nothing, ContinuousRectangularSearchSpace{Float64}([-5.0, -5.0], [5.0, 5.0], [10.0, 10.0]))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/Problem.jl#L179-L204">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.NonlinearProblem-Union{Tuple{SS}, Tuple{F}, Tuple{F, SS}} where {F&lt;:Function, SS&lt;:GlobalOptimization.SearchSpace}" href="#GlobalOptimization.NonlinearProblem-Union{Tuple{SS}, Tuple{F}, Tuple{F, SS}} where {F&lt;:Function, SS&lt;:GlobalOptimization.SearchSpace}"><code>GlobalOptimization.NonlinearProblem</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">NonlinearProblem(f, [g], ss)</code></pre><p>Constructs a nonlinear problem with nonlinear function <code>f</code>, optional Jacobian <code>g</code>, and a search space.</p><p><strong>Arguments</strong></p><ul><li><code>f::F</code>: The nonlinear function.</li><li><code>g::G</code>: The Jacobian of the nonlinear function.</li><li><code>ss::SS</code>: The search space.</li></ul><p><strong>Returns</strong></p><ul><li><code>NonlinearProblem{has_penalty, ContinuousRectangularSearchSpace, F, G}</code></li></ul><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using GlobalOptimization;
julia&gt; f(x) = [x[1] - 2.0, x[2] - 2.0]
julia&gt; LB = [-5.0, -5.0];
julia&gt; UB = [ 5.0, 5.0];
julia&gt; ss = ContinuousRectangularSearchSpace(LB, UB);
julia&gt; prob = NonlinearProblem(f, ss)
NonlinearProblem{Val{false}(), ContinuousRectangularSearchSpace{Float64}, typeof(f), Nothing}(f, nothing, ContinuousRectangularSearchSpace{Float64}([-5.0, -5.0], [5.0, 5.0], [10.0, 10.0]))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/Problem.jl#L229-L252">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.OptimizationProblem" href="#GlobalOptimization.OptimizationProblem"><code>GlobalOptimization.OptimizationProblem</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">OptimizationProblem{has_penalty, SS, F, G}</code></pre><p>An optimization problem. Contains the objective function and search space.</p><p><strong>Fields</strong></p><ul><li><code>f::F</code>: The objective function.</li><li><code>g!::G</code>: The gradient of the objective function.</li><li><code>ss::SS</code>: The search space.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/Problem.jl#L23-L32">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.OptimizationProblem-Union{Tuple{F}, Tuple{F, AbstractVector{&lt;:Real}, AbstractVector{&lt;:Real}}} where F&lt;:Function" href="#GlobalOptimization.OptimizationProblem-Union{Tuple{F}, Tuple{F, AbstractVector{&lt;:Real}, AbstractVector{&lt;:Real}}} where F&lt;:Function"><code>GlobalOptimization.OptimizationProblem</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">OptimizationProblem(f, [g], LB, UB)</code></pre><p>Constructs an optimization problem with objective function <code>f</code>, optional gradient <code>g</code>, and a <code>ContinuousRectangularSearchSpace</code> defined by <code>LB</code> and <code>UB</code>.</p><p><strong>Arguments</strong></p><ul><li><code>f::F</code>: The objective function.</li><li><code>LB::AbstractVector{&lt;:Real}</code>: The lower bounds of the search space.</li><li><code>UB::AbstractVector{&lt;:Real}</code>: The upper bounds of the search space.</li></ul><p><strong>Returns</strong></p><ul><li><code>OptimizationProblem{ContinuousRectangularSearchSpace, F}</code></li></ul><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using GlobalOptimization;
julia&gt; f(x) = sum(x.^2); # Simple sphere function
julia&gt; LB = [-1.0, 0.0];
julia&gt; UB = [ 1.0, 2.0];
julia&gt; prob = OptimizationProblem(f, LB, UB)
OptimizationProblem{ContinuousRectangularSearchSpace{Float64}, typeof(f)}(f, ContinuousRectangularSearchSpace{Float64}([-1.0, 0.0], [1.0, 2.0], [2.0, 2.0]))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/Problem.jl#L125-L149">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.OptimizationProblem-Union{Tuple{F}, Tuple{has_penalty}, Tuple{T}, Tuple{F, GlobalOptimization.SearchSpace{T}}} where {T, has_penalty, F&lt;:Function}" href="#GlobalOptimization.OptimizationProblem-Union{Tuple{F}, Tuple{has_penalty}, Tuple{T}, Tuple{F, GlobalOptimization.SearchSpace{T}}} where {T, has_penalty, F&lt;:Function}"><code>GlobalOptimization.OptimizationProblem</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">OptimizationProblem{has_penalty}(f::F, [g::G], ss::SS)</code></pre><p>Constructs an optimization problem with objective function <code>f</code>, optional gradient <code>g</code>, and search space <code>ss</code>. If has_penalty is specified as true, then the objective function must return a Tuple{T,T} for a given x of type AbstractArray{T}.</p><p><strong>Arguments</strong></p><ul><li><code>f::F</code>: The objective function.</li><li><code>g::G</code>: The gradient of the objective function.</li><li><code>ss::SS</code>: The search space.</li></ul><p><strong>Returns</strong></p><ul><li><code>OptimizationProblem{SS, F}</code></li></ul><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using GlobalOptimization;
julia&gt; f(x) = sum(x.^2); # Simple sphere function
julia&gt; LB = [-1.0, 0.0];
julia&gt; UB = [ 1.0, 2.0];
julia&gt; ss = ContinuousRectangularSearchSpace(LB, UB);
julia&gt; prob = OptimizationProblem(f, ss)
OptimizationProblem{ContinuousRectangularSearchSpace{Float64}, typeof(f)}(f, ContinuousRectangularSearchSpace{Float64}([-1.0, 0.0], [1.0, 2.0], [2.0, 2.0]))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/Problem.jl#L39-L64">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.OptimizationProblem-Union{Tuple{SS}, Tuple{F}, Tuple{F, SS}} where {F&lt;:Function, SS&lt;:GlobalOptimization.SearchSpace}" href="#GlobalOptimization.OptimizationProblem-Union{Tuple{SS}, Tuple{F}, Tuple{F, SS}} where {F&lt;:Function, SS&lt;:GlobalOptimization.SearchSpace}"><code>GlobalOptimization.OptimizationProblem</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">OptimizationProblem(f, [g], ss)</code></pre><p>Constructs an optimization problem with objective function <code>f</code>, optimal gradient <code>g</code>, and a search space.</p><p><strong>Arguments</strong></p><ul><li><code>f::F</code>: The objective function.</li><li><code>g::G</code>: The gradient of the objective function.</li><li><code>ss::SS</code>: The search space.</li></ul><p><strong>Returns</strong></p><ul><li><code>OptimizationProblem{ContinuousRectangularSearchSpace, F}</code></li></ul><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using GlobalOptimization;
julia&gt; f(x) = sum(x.^2); # Simple sphere function
julia&gt; LB = [-1.0, 0.0];
julia&gt; UB = [ 1.0, 2.0];
julia&gt; prob = OptimizationProblem(f, ContinuousRectangularSearchSpace(LB, UB))
OptimizationProblem{ContinuousRectangularSearchSpace{Float64}, typeof(f)}(f, ContinuousRectangularSearchSpace{Float64}([-1.0, 0.0], [1.0, 2.0], [2.0, 2.0]))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/Problem.jl#L91-L113">source</a></section></article><h2 id="Search-Space"><a class="docs-heading-anchor" href="#Search-Space">Search Space</a><a id="Search-Space-1"></a><a class="docs-heading-anchor-permalink" href="#Search-Space" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.ContinuousRectangularSearchSpace" href="#GlobalOptimization.ContinuousRectangularSearchSpace"><code>GlobalOptimization.ContinuousRectangularSearchSpace</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">ContinuousRectangularSearchSpace{T &lt;: AbstractFloat}</code></pre><p>A <code>RectangularSearchSpace</code> formed by a single continuous set.</p><p><strong>Fields</strong></p><ul><li><code>dim_min::Vector{T}</code>: A vector of minimum values for each dimension.</li><li><code>dim_max::Vector{T}</code>: A vector of maximum values for each dimension.</li><li><code>dim_delta::Vector{T}</code>: A vector of the difference between the maximum and minimum values for each dimension.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/SearchSpace.jl#L23-L32">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.ContinuousRectangularSearchSpace-Union{Tuple{T2}, Tuple{T1}, Tuple{AbstractVector{T1}, AbstractVector{T2}}} where {T1&lt;:Real, T2&lt;:Real}" href="#GlobalOptimization.ContinuousRectangularSearchSpace-Union{Tuple{T2}, Tuple{T1}, Tuple{AbstractVector{T1}, AbstractVector{T2}}} where {T1&lt;:Real, T2&lt;:Real}"><code>GlobalOptimization.ContinuousRectangularSearchSpace</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">ContinuousRectangularSearchSpace(dim_min::AbstractVector{T}, dim_max::AbstractVector{T})</code></pre><p>Constructs a new <code>ContinuousRectangularSearchSpace</code> with minimum values <code>dim_min</code> and maximum values <code>dim_max</code>.</p><p><strong>Arguments</strong></p><ul><li><code>dim_min::AbstractVector{T}</code>: A vector of minimum values for each dimension.</li><li><code>dim_max::AbstractVector{T}</code>: A vector of maximum values for each dimension.</li></ul><p><strong>Returns</strong></p><ul><li><code>ContinuousRectangularSearchSpace{T}</code></li></ul><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using GlobalOptimization;
julia&gt; LB = [-1.0, 0.0];
julia&gt; UB = [ 1.0, 2.0];
julia&gt; ss = ContinuousRectangularSearchSpace(LB, UB)
ContinuousRectangularSearchSpace{Float64}([-1.0, 0.0], [1.0, 2.0], [2.0, 2.0])</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/SearchSpace.jl#L38-L58">source</a></section></article><h2 id="Optimization"><a class="docs-heading-anchor" href="#Optimization">Optimization</a><a id="Optimization-1"></a><a class="docs-heading-anchor-permalink" href="#Optimization" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.optimize!-Tuple{GlobalOptimization.AbstractOptimizer}" href="#GlobalOptimization.optimize!-Tuple{GlobalOptimization.AbstractOptimizer}"><code>GlobalOptimization.optimize!</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">optimize!(opt::AbstractOptimizer)</code></pre><p>Perform optimization using the optimizer <code>opt</code>. Returns the results of the optimization.</p><p><strong>Arguments</strong></p><ul><li><code>opt::AbstractOptimizer</code>: The optimizer to use.</li></ul><p><strong>Returns</strong></p><ul><li><code>Results</code>: The results of the optimization. See the <a href="../internal/temp/#GlobalOptimization.Results">Results</a> docstring for details   on its contents.</li></ul><p><strong>Example</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using GlobalOptimization
julia&gt; f(x) = sum(x.^2) # Simple sphere function
julia&gt; prob = OptimizationProblem(f, [-1.0, 0.0], [1.0, 2.0])
julia&gt; pso = SerialPSO(prob)
julia&gt; results = optimize!(pso)
Results:
 - Best function value: 6.696180996034206e-20
 - Best candidate: [-2.587698010980842e-10, 0.0]
 - Iterations: 26
 - Time: 0.004351139068603516 seconds
 - Exit flag: MAXIMUM_STALL_ITERATIONS_EXCEEDED</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/Optimizers.jl#L169-L195">source</a></section></article><h2 id="Population-Initialization"><a class="docs-heading-anchor" href="#Population-Initialization">Population Initialization</a><a id="Population-Initialization-1"></a><a class="docs-heading-anchor-permalink" href="#Population-Initialization" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.LatinHypercubeInitialization" href="#GlobalOptimization.LatinHypercubeInitialization"><code>GlobalOptimization.LatinHypercubeInitialization</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">LatinHypercubeInitialization</code></pre><p>Initializes a population using optimal Latin hypercube sampling as implemented in <a href="https://github.com/MrUrq/LatinHypercubeSampling.jl/tree/master">LatinHypercubeSampling.jl</a>.</p><p><strong>Fields:</strong></p><ul><li><code>gens::Int</code>: Number of GA generations to use to generate the Latin hypercube samples.</li><li><code>rng::U</code>: Random number generator to use for the Latin hypercube sampling.</li><li><code>pop_size::Int</code>: Size of the GA population used to generate the Latin hypercube samples.</li><li><code>n_tour::Int</code>: Number of tours to use in the GA.</li><li><code>p_tour::Float64</code>: Probability of tour to use in the GA.</li><li><code>inter_sample_weight::Float64</code>: Weight of the inter-sample distance in the GA.</li><li><code>periodic_ae::Bool</code>: Whether to use periodic adaptive evolution in the GA.</li><li><code>ae_power::Float64</code>: Power of the adaptive evolution in the GA.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/Population.jl#L87-L102">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.LatinHypercubeInitialization-Tuple{Int64}" href="#GlobalOptimization.LatinHypercubeInitialization-Tuple{Int64}"><code>GlobalOptimization.LatinHypercubeInitialization</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">LatinHypercubeInitialization(gens::Int = 10; kwargs...)</code></pre><p>Initializes a Latin hypercube sampling method with the given parameters.</p><p><strong>Arguments</strong></p><ul><li><code>gens::Int</code>: Number of GA generations to use to generate the Latin hypercube samples.   Defaults to 10.</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>rng::U</code>: Random number generator to use for the Latin hypercube sampling.   Defaults to <code>Random.GLOBAL_RNG</code>.</li><li><code>pop_size::Int</code>: Size of the GA population used to generate the Latin hypercube samples.   Defaults to 100.</li><li><code>n_tour::Int</code>: Number of tours to use in the GA. Defaults to 2.</li><li><code>p_tour::Float64</code>: Probability of tour to use in the GA. Defaults to 0.8.</li><li><code>inter_sample_weight::Float64</code>: Weight of the inter-sample distance in the GA.   Defaults to 1.0.</li><li><code>periodic_ae::Bool</code>: Whether to use periodic adaptive evolution in the GA.   Defaults to false.</li><li><code>ae_power::Float64</code>: Power of the adaptive evolution in the GA. Defaults to 2.0.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/Population.jl#L113-L134">source</a></section></article><h2 id="Function-Evaluation-Methods"><a class="docs-heading-anchor" href="#Function-Evaluation-Methods">Function Evaluation Methods</a><a id="Function-Evaluation-Methods-1"></a><a class="docs-heading-anchor-permalink" href="#Function-Evaluation-Methods" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.SerialFunctionEvaluation" href="#GlobalOptimization.SerialFunctionEvaluation"><code>GlobalOptimization.SerialFunctionEvaluation</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">SerialFunctionEvaluation</code></pre><p>A function evaluation method that evaluates the fitness of a candidate in serial.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/Evaluator.jl#L9-L13">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.SerialFunctionEvaluation-Tuple{}" href="#GlobalOptimization.SerialFunctionEvaluation-Tuple{}"><code>GlobalOptimization.SerialFunctionEvaluation</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">SerialFunctionEvaluation()</code></pre><p>Construct a <code>SerialFunctionEvaluation</code> object.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/Evaluator.jl#L15-L19">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.ThreadedFunctionEvaluation" href="#GlobalOptimization.ThreadedFunctionEvaluation"><code>GlobalOptimization.ThreadedFunctionEvaluation</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">ThreadedFunctionEvaluation{S &lt;: ChunkSplitters.Split}</code></pre><p>A function evaluation method that evaluates the fitness of a candidate in parallel using     multi-threading from Base.Threads.jl.</p><p><strong>Fields</strong></p><ul><li><code>n::Int</code>: The number of batch jobs to split the workload into using   <a href="https://github.com/JuliaFolds2/ChunkSplitters.jl">ChunkSplitters.jl</a>.</li><li><code>split::S</code>: The chunk splitter to use. See <a href="https://github.com/JuliaFolds2/ChunkSplitters.jl">ChunkSplitters.jl</a>   for more information.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/Evaluator.jl#L25-L36">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.ThreadedFunctionEvaluation-Tuple{}" href="#GlobalOptimization.ThreadedFunctionEvaluation-Tuple{}"><code>GlobalOptimization.ThreadedFunctionEvaluation</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">ThreadedFunctionEvaluation(
    n::Int=Threads.nthreads(),
    split::S=ChunkSplitters.RoundRobin(),
)</code></pre><p>Construct a <code>ThreadedFunctionEvaluation</code> object.</p><p><strong>Keyword Arguments</strong></p><ul><li><code>n::Int</code>: The number of batch jobs to split the workload into using   <a href="https://github.com/JuliaFolds2/ChunkSplitters.jl">ChunkSplitters.jl</a>.</li><li><code>split::S</code>: The chunk splitter to use. See <a href="https://github.com/JuliaFolds2/ChunkSplitters.jl">ChunkSplitters.jl</a>   for more information.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/Evaluator.jl#L41-L54">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.PolyesterFunctionEvaluation" href="#GlobalOptimization.PolyesterFunctionEvaluation"><code>GlobalOptimization.PolyesterFunctionEvaluation</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">PolyesterFunctionEvaluation</code></pre><p>A function evaluation method that evaluates the fitness of a candidate in parallel using     <a href="https://github.com/JuliaSIMD/Polyester.jl">Polyester.jl</a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/Evaluator.jl#L62-L67">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.PolyesterFunctionEvaluation-Tuple{}" href="#GlobalOptimization.PolyesterFunctionEvaluation-Tuple{}"><code>GlobalOptimization.PolyesterFunctionEvaluation</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">PolyesterFunctionEvaluation()</code></pre><p>Construct a <code>PolyesterFunctionEvaluation</code> object.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/Evaluator.jl#L69-L73">source</a></section></article><h2 id="Algorithms"><a class="docs-heading-anchor" href="#Algorithms">Algorithms</a><a id="Algorithms-1"></a><a class="docs-heading-anchor-permalink" href="#Algorithms" title="Permalink"></a></h2><h3 id="Particle-Swarm-Optimization"><a class="docs-heading-anchor" href="#Particle-Swarm-Optimization">Particle Swarm Optimization</a><a id="Particle-Swarm-Optimization-1"></a><a class="docs-heading-anchor-permalink" href="#Particle-Swarm-Optimization" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.PSO" href="#GlobalOptimization.PSO"><code>GlobalOptimization.PSO</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">PSO</code></pre><p>Particle Swarm Optimization (PSO) algorithm.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/PSO/PSO.jl#L33-L37">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.PSO-Union{Tuple{GlobalOptimization.AbstractProblem{has_penalty, SS}}, Tuple{has_penalty}, Tuple{SS}, Tuple{T}} where {T&lt;:AbstractFloat, SS&lt;:ContinuousRectangularSearchSpace{T}, has_penalty}" href="#GlobalOptimization.PSO-Union{Tuple{GlobalOptimization.AbstractProblem{has_penalty, SS}}, Tuple{has_penalty}, Tuple{SS}, Tuple{T}} where {T&lt;:AbstractFloat, SS&lt;:ContinuousRectangularSearchSpace{T}, has_penalty}"><code>GlobalOptimization.PSO</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">PSO(prob::AbstractProblem{has_penalty,SS}; kwargs...)</code></pre><p>Constructs a PSO algorithm with the given options.</p><p><strong>Arguments</strong></p><ul><li><code>prob::AbstractProblem{has_penalty,SS}</code>: The problem to solve.</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>eval_method::AbstractFunctionEvaluationMethod=SerialFunctionEvaluation()</code>: The method to use for evaluating the objective function.</li><li><code>num_particles::Int = 100</code>: The number of particles to use.</li><li><code>population_initialization::AbstractPopulationInitialization = UniformInitialization()</code>: The method to use for initializing the population.</li><li><code>velocity_update::AbstractVelocityUpdateScheme = MATLABVelocityUpdate()</code>: The method to use for updating the velocity of the particles.</li><li><code>initial_space::Union{Nothing,ContinuousRectangularSearchSpace}=nothing</code>: The initial bounds for the search space.</li><li><code>max_iterations::Integer=1000</code>: The maximum number of iterations.</li><li><code>function_tolerance::Real=1e-6</code>: The function tolerance (stall-based stopping criteria).</li><li><code>max_stall_time::Real=60.0</code>: The maximum stall time (in seconds).</li><li><code>max_stall_iterations::Integer=100</code>: The maximum number of stall iterations.</li><li><code>max_time::Real=60.0</code>: The maximum time (in seconds) to allow for optimization.</li><li><code>min_cost::Real=(-Inf)</code>: The minimum cost to allow for optimization.</li><li><code>function_value_check::Union{Val{false},Val{true}}=Val(true)</code>: Whether to check the function value   for bad values (i.e., Inf or NaN).</li><li><code>show_trace::Union{Val{false},Val{true}}=Val(false)</code>: Whether to show the trace.</li><li><code>save_trace::Union{Val{false},Val{true}}=Val(false)</code>: Whether to save the trace.</li><li><code>save_file::String=&quot;trace.txt&quot;</code>: The file to save the trace to.</li><li><code>trace_level::TraceLevel=TraceMinimal(1)</code>: The trace level to use.</li></ul><p><strong>Returns</strong></p><ul><li><code>PSO</code>: The PSO algorithm.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/PSO/PSO.jl#L59-L88">source</a></section></article><h4 id="Velocity-Update-Schemes"><a class="docs-heading-anchor" href="#Velocity-Update-Schemes">Velocity Update Schemes</a><a id="Velocity-Update-Schemes-1"></a><a class="docs-heading-anchor-permalink" href="#Velocity-Update-Schemes" title="Permalink"></a></h4><p>The PSO velocity update is the primary mechanism that drives the stochastic  optimization process. The currently implemented velocity update schemes can  be described by the following:</p><p>Consider a <em>swarm</em> of <span>$n$</span> particles <span>$\mathcal{S} = \{\mathbf{p}_i\}_{i=1,2,\dots,n}$</span>. Each particle <span>$\mathbf{p}_i$</span> has the following attributes associated with it:</p><ul><li>position: <span>$\mathbf{x}_i$</span></li><li>velocity: <span>$\mathbf{v}_i$</span>,</li><li>best position: <span>$\mathbf{x}_{i,b}$</span></li><li>best fitness: <span>$f_{i,b} = f(\mathbf{x}_{i,b})$</span></li></ul><p>At each iteration of the PSO algorithm, the velocity of each particle is updated prior to  updating the position of each particle with <span>$\mathbf{x}_i = \mathbf{x}_i + \mathbf{v}_i$</span>. This velocity update is described (for the <span>$i$</span>-th particle) by the following expression:</p><p><span>$\mathbf{v}_i = w \mathbf{v}_i +     y_1 \mathbf{r}_1 (\mathbf{x}_{i,b} - \mathbf{x}_i) +     y_2 \mathbf{r}_2 (\mathbf{x}_b - \mathbf{x}_i)$</span></p><p>where <span>$w$</span> is the inertia,  <span>$r_1$</span> and <span>$r_2$</span> are realizations of a random vector described by the multivariate uniform distribution <span>$\mathcal{U}(\mathbf{0}, \mathbf{1})$</span>, <span>$y_1$</span> is the self-adjustment weight, <span>$y_2$</span> is the social adjustment weight, and <span>$\mathbf{x}_{b}$</span> is the best position in the neighborhood of the <span>$i$</span>-th particle <span>$\mathcal{N}_i$</span>. That is, <span>$\mathbf{x}_b = \underset{x\in\mathcal{X}_b}{\mathrm{argmin}}(f(x))$</span> where <span>$\mathcal{X}_{b,i} = \{ \mathbf{x}_{i,b} \}_{\mathbf{p}_i \in \mathcal{N}_i}$</span> and <span>$\mathcal{N}_i$</span> is a set containing a randomly selected subset of the particles in <span>$\mathcal{S}$</span> (not including <span>$\mathbf{p}_i$</span>). Both the size of <span>$\mathcal{N}_i$</span> and  the inertia <span>$w$</span> are handle differently depending on the velocity update scheme used.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.MATLABVelocityUpdate" href="#GlobalOptimization.MATLABVelocityUpdate"><code>GlobalOptimization.MATLABVelocityUpdate</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">MATLABVelocityUpdate &lt;: AbstractRandomNeighborhoodVelocityUpdateScheme</code></pre><p>A velocity update scheme employed by the <a href="https://www.mathworks.com/help/gads/particle-swarm-optimization-algorithm.html">MATLAB PSO algorithm</a>. This scheme is described as follows:</p><p>In this velocity update scheme, the size of the neighborhood, as well as the inertia weight, are adaptively updated as follows:</p><p><em>Prior to First Iteration:</em></p><ol><li><p>Set the inertial weight <span>$w$</span>: <code>w = inertia_range[2]</code></p></li><li><p>Set the minimum neighborhood size: <code>minimum_neighborhood_size = max(2, floor(Int, swarm_size * minimum_neighborhood_fraction))</code></p></li><li><p>Set the neighborhood size: <code>N = minimum_neighborhood_size</code></p></li><li><p>Set counter: <code>c = 0</code></p></li></ol><p><em>After Evaluating Swarm Fitness Each Iteration:</em></p><ul><li>If the best fitness of the swarm has improved:<ol><li>Decrease the counter: <code>c = max(0, c - 1)</code></li><li>Set the neighborhood size to the minimum: <code>N = minimum_neighborhood_size</code></li><li>Update the inertia weight:<ul><li>If <code>c &lt; 2; w = 2.0 * w</code></li><li>If <code>c &gt; 5; w = 0.5 * w</code></li><li>Clamp <code>w</code> to lie in <code>[inertia_range[1], inertia_range[2]]</code></li></ul></li></ol></li><li>If the best fitness of the swarm has not improved:<ol><li>Increase the counter: <code>c += 1</code></li><li>Increase the neighborhood size:  <code>N = min(N + minimum_neighborhood_size, swarm_size - 1)</code></li></ol></li></ul><p><strong>Fields</strong></p><ul><li><code>swarm_size::Int</code>: The size of the swarm.</li><li><code>inertia_range::Tuple{Float64,Float64}</code>: The range of inertia weights.</li><li><code>minimum_neighborhood_fraction::Float64</code>: The minimum fraction of the swarm size to be used as the neighborhood size.</li><li><code>minimum_neighborhood_size::Int</code>: The minimum neighborhood size.</li><li><code>self_adjustment_weight::Float64</code>: The self-adjustment weight.</li><li><code>social_adjustment_weight::Float64</code>: The social adjustment weight.</li><li><code>w::Float64</code>: The inertia weight.</li><li><code>c::Int</code>: The stall iteration counter.</li><li><code>N::Int</code>: The neighborhood size.</li><li><code>index_vector::Vector{UInt16}</code>: A vector used to store the indices of the particles in the   swarm. Used for random neighborhood selection without allocations.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/PSO/velocity_update.jl#L32-L73">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.MATLABVelocityUpdate-Tuple{}" href="#GlobalOptimization.MATLABVelocityUpdate-Tuple{}"><code>GlobalOptimization.MATLABVelocityUpdate</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">MATLABVelocityUpdate(;
    inertia_range::Tuple{AbstractFloat,AbstractFloat}=(0.1, 1.0),
    minimum_neighborhood_fraction::AbstractFloat=0.25,
    self_adjustment_weight::AbstractFloat=1.49,
    social_adjustment_weight::AbstractFloat=1.49,
)</code></pre><p>Create a new instance of the <code>MATLABVelocityUpdate</code> velocity update scheme.</p><p><strong>Keyword Arguments</strong></p><ul><li><code>inertia_range::Tuple{AbstractFloat,AbstractFloat}</code>: The range of inertia weights.</li><li><code>minimum_neighborhood_fraction::AbstractFloat</code>: The minimum fraction of the swarm size to be used as the neighborhood size.</li><li><code>self_adjustment_weight::AbstractFloat</code>: The self-adjustment weight.</li><li><code>social_adjustment_weight::AbstractFloat</code>: The social adjustment weight.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/PSO/velocity_update.jl#L91-L106">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.CSRNVelocityUpdate" href="#GlobalOptimization.CSRNVelocityUpdate"><code>GlobalOptimization.CSRNVelocityUpdate</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">CSRNVelocityUpdate &lt;: AbstractRandomNeighborhoodVelocityUpdateScheme</code></pre><p>A velocity update scheme employed a Constant Size Random Neighborhood (CSRN).</p><p>In this velocity update scheme, the size of the neighborhood is constant and set based on the specified <code>neighborhood_fraction</code> (i.e., the fraction of the swarm size to be considered to lie in a neighborhood). However, the inertia is adaptively updated as follows:</p><p><em>Prior to First Iteration:</em>  Set the inertial weight <span>$w$</span>: <code>w = inertia_range[2]</code></p><p><em>After Evaluating Swarm Fitness Each Iteration:</em></p><ul><li>If <code>stall_iteration &lt; 2; w = 2.0 * w</code></li><li>If <code>stall_iteration &gt; 5; w = 0.5 * w</code></li><li>Clamp <code>w</code> to lie in <code>[inertia_range[1], inertia_range[2]]</code></li></ul><p>Note that <code>stall_iteration</code> is the number of iterations since the global best position found so far was improved by a specified <code>function_tolerance</code> (see PSO keyword arguments).</p><p><strong>Fields</strong></p><ul><li><code>inertia_range::Tuple{Float64,Float64}</code>: The range of inertia weights.</li><li><code>neighborhood_fraction::Float64</code>: The fraction of the swarm size to be used as the neighborhood size.</li><li><code>N::Int</code>: The neighborhood size.</li><li><code>self_adjustment_weight::Float64</code>: The self-adjustment weight.</li><li><code>social_adjustment_weight::Float64</code>: The social adjustment weight.</li><li><code>w::Float64</code>: The inertia weight.</li><li><code>index_vector::Vector{UInt16}</code>: A vector used to store the indices of the particles in the   swarm. Used for random neighborhood selection without allocations.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/PSO/velocity_update.jl#L136-L164">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.CSRNVelocityUpdate-Tuple{}" href="#GlobalOptimization.CSRNVelocityUpdate-Tuple{}"><code>GlobalOptimization.CSRNVelocityUpdate</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">CSRNVelocityUpdate(;
    inertia_range::Tuple{AbstractFloat,AbstractFloat}=(0.1, 1.0),
    neighborhood_fraction::AbstractFloat=0.25,
    self_adjustment_weight::AbstractFloat=1.49,
    social_adjustment_weight::AbstractFloat=1.49,
)</code></pre><p>Create a new instance of the <code>CSRNVelocityUpdate</code> velocity update scheme.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/PSO/velocity_update.jl#L179-L188">source</a></section></article><h3 id="Differential-Evolution"><a class="docs-heading-anchor" href="#Differential-Evolution">Differential Evolution</a><a id="Differential-Evolution-1"></a><a class="docs-heading-anchor-permalink" href="#Differential-Evolution" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.DE" href="#GlobalOptimization.DE"><code>GlobalOptimization.DE</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>DE</p><p>Differential Evolution (DE) algorithm.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/DE/DE.jl#L54-L58">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.DE-Union{Tuple{GlobalOptimization.AbstractProblem{has_penalty, SS}}, Tuple{has_penalty}, Tuple{SS}, Tuple{T}, Tuple{CP}, Tuple{MP}} where {MP&lt;:GlobalOptimization.AbstractMutationParameters, CP&lt;:GlobalOptimization.AbstractCrossoverParameters, T&lt;:AbstractFloat, SS&lt;:ContinuousRectangularSearchSpace{T}, has_penalty}" href="#GlobalOptimization.DE-Union{Tuple{GlobalOptimization.AbstractProblem{has_penalty, SS}}, Tuple{has_penalty}, Tuple{SS}, Tuple{T}, Tuple{CP}, Tuple{MP}} where {MP&lt;:GlobalOptimization.AbstractMutationParameters, CP&lt;:GlobalOptimization.AbstractCrossoverParameters, T&lt;:AbstractFloat, SS&lt;:ContinuousRectangularSearchSpace{T}, has_penalty}"><code>GlobalOptimization.DE</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">DE(prob::AbstractProblem{has_penalty,SS}; kwargs...)</code></pre><p>Construct a serial Differential Evolution (DE) algorithm with the given options.</p><p><strong>Arguments</strong></p><ul><li><code>prob::AbstractProblem{has_penalty,SS}</code>: The problem to solve.</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>eval_method::AbstractFunctionEvaluationMethod=SerialFunctionEvaluation()</code>: The method to use for evaluating the objective function.</li><li><code>num_candidates::Integer=100</code>: The number of candidates in the population.</li><li><code>population_initialization::AbstractPopulationInitialization=UniformInitialization()</code>: The population initialization method.</li><li><code>mutation_params::MP=SelfMutationParameters(Rand1())</code>: The mutation strategy parameters.</li><li><code>crossover_params::CP=BinomialCrossoverParameters(0.6)</code>: The crossover strategy parameters.</li><li><code>initial_space::Union{Nothing,ContinuousRectangularSearchSpace}=nothing</code>: The initial bounds for the search space.</li><li><code>max_iterations::Integer=1000</code>: The maximum number of iterations.</li><li><code>function_tolerance::Real=1e-6</code>: The function tolerance (stall-based stopping criteria).</li><li><code>max_stall_time::Real=60.0</code>: The maximum stall time (in seconds).</li><li><code>max_stall_iterations::Integer=100</code>: The maximum number of stall iterations.</li><li><code>max_time::Real=60.0</code>: The maximum time (in seconds) to allow for optimization.</li><li><code>min_cost::Real=(-Inf)</code>: The minimum cost to allow for optimization.</li><li><code>function_value_check::Union{Val{false},Val{true}}=Val(true)</code>: Whether to check the function value   for bad values (i.e., Inf or NaN).</li><li><code>show_trace::Union{Val{false},Val{true}}=Val(false)</code>: Whether to show the trace.</li><li><code>save_trace::Union{Val{false},Val{true}}=Val(false)</code>: Whether to save the trace.</li><li><code>save_file::String=&quot;trace.txt&quot;</code>: The file to save the trace to.</li><li><code>trace_level::TraceLevel=TraceMinimal(1)</code>: The trace level to use.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/DE/DE.jl#L81-L108">source</a></section></article><h4 id="Mutation-Parameters"><a class="docs-heading-anchor" href="#Mutation-Parameters">Mutation Parameters</a><a id="Mutation-Parameters-1"></a><a class="docs-heading-anchor-permalink" href="#Mutation-Parameters" title="Permalink"></a></h4><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.MutationParameters" href="#GlobalOptimization.MutationParameters"><code>GlobalOptimization.MutationParameters</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">MutationParameters{
    AS&lt;:AbstractAdaptationStrategy,
    MS&lt;:AbstractMutationOperator,
    S&lt;:AbstractSelector,
    D,
}</code></pre><p>The parameters for a DE mutation strategy that applies to all current and future candidates in the population.</p><p><strong>Fields</strong></p><ul><li><code>F1::Float64</code>: The F₁ weight in the unified mutation strategy.</li><li><code>F2::Float64</code>: The F₂ weight in the unified mutation strategy.</li><li><code>F3::Float64</code>: The F₃ weight in the unified mutation strategy.</li><li><code>F4::Float64</code>: The F₄ weight in the unified mutation strategy.</li><li><code>sel&lt;:AbstractSelector</code>: The selector used to select the candidates considered in   mutation.</li><li><code>dist&lt;:Distribution{Univariate,Continuous}</code>: The distribution used to adapt the mutation   parameters. Note that this should generally be a distribution from   <a href="https://juliastats.org/Distributions.jl/latest/">Distributions.jl</a>, but the only strict   requirement is that rand(dist) returns a floating point value.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/DE/mutation.jl#L275-L297">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.MutationParameters-NTuple{4, Any}" href="#GlobalOptimization.MutationParameters-NTuple{4, Any}"><code>GlobalOptimization.MutationParameters</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">MutationParameters(F1, F2, F3, F4; sel=SimpleSelector())</code></pre><p>Creates a <code>MutationParameters</code> object with the specified (constant) mutation parameters. These constant mutation parameters are used for all candidates in the population and define a unified mutation strategy as defined in Ji Qiang and Chad Mitchell &quot;A Unified Differential Evolution Algorithm for Global Optimization,&quot; 2014, <a href="https://www.osti.gov/servlets/purl/1163659">https://www.osti.gov/servlets/purl/1163659</a></p><p><strong>Arguments</strong></p><ul><li><code>F1::Float64</code>: The F₁ weight in the unified mutation strategy.</li><li><code>F2::Float64</code>: The F₂ weight in the unified mutation strategy.</li><li><code>F3::Float64</code>: The F₃ weight in the unified mutation strategy.</li><li><code>F4::Float64</code>: The F₄ weight in the unified mutation strategy.</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>sel::AbstractSelector</code>: The selector used to select the candidates considered in   mutation. Defaults to <code>SimpleSelector()</code>.</li></ul><p><strong>Returns</strong></p><ul><li><code>MutationParameters{NoAdaptation,Unified,typeof(sel),Nothing}</code>: A mutation parameters   object with the specified mutation parameters and selector.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using GlobalOptimization
julia&gt; params = MutationParameters(0.5, 0.5, 0.5, 0.5)
MutationParameters{GlobalOptimization.NoAdaptation, Unified, SimpleSelector, Nothing}(0.5, 0.5, 0.5, 0.5, SimpleSelector(), nothing)</code></pre><pre><code class="language-julia-repl hljs">julia&gt; using GlobalOptimization
julia&gt; params = MutationParameters(0.5, 0.5, 0.5, 0.5; sel=RadiusLimitedSelector(2))
MutationParameters{GlobalOptimization.NoAdaptation, Unified, RadiusLimitedSelector, Nothing}(0.5, 0.5, 0.5, 0.5, RadiusLimitedSelector(2, UInt16[0x6cf0, 0x0c33, 0x0001, 0x0000, 0x0560]), nothing)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/DE/mutation.jl#L308-L342">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.MutationParameters-Tuple{GlobalOptimization.AbstractMutationOperator}" href="#GlobalOptimization.MutationParameters-Tuple{GlobalOptimization.AbstractMutationOperator}"><code>GlobalOptimization.MutationParameters</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">MutationParameters(
    strategy::MS;
    dist=default_mutation_dist,
    sel=SimpleSelector(),
)</code></pre><p>Creates a MutationParameters object with the specified mutation strategy with mutation parameter random adaptation. The mutation parameters are adaptively sampled from the provided <code>dist</code>, clamped to the range (0, 1].</p><p><strong>Arguments</strong></p><ul><li><code>strategy::MS</code>: The mutation strategy to use. This should be one of the mutation   strategies defined in this module (e.g., <code>Rand1</code>, <code>Best2</code>, etc.).</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><p><code>dist::Distribution{Univariate,Continuous}</code>: The distribution used to adapt the   mutation parameters each iteration. Note that this should generally be a   distribution from   <a href="https://juliastats.org/Distributions.jl/latest/">Distributions.jl</a>, but the only   strict requirement is that rand(dist) returns a floating point value. Defaults to   <code>GlobalOptimization.default_mutation_dist</code>, which is a mixture model comprised of   two Cauchy distributions, with probability density given by:</p><p><span>$f_{mix}(x; \mu, \sigma) = 0.5 f(x;\mu_1,\sigma_1) + 0.5 f(x;\mu_2,\sigma_2)$</span>.</p><p>where <span>$\mu = \{0.65, 1.0\}$</span> and <span>$\sigma = \{0.1, 0.1\}$</span>.</p></li><li><p><code>sel::AbstractSelector</code>: The selector used to select the candidates considered in   mutation. Defaults to <code>SimpleSelector()</code>.</p></li></ul><p><strong>Returns</strong></p><ul><li><code>MutationParameters{RandomAdaptation,typeof(strategy),typeof(sel),typeof(dist)}</code>: A   mutation parameters object with the specified mutation strategy and selector.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using GlobalOptimization
julia&gt; params = MutationParameters(Rand1())
MutationParameters{GlobalOptimization.RandomAdaptation, Rand1, SimpleSelector, Distributions.MixtureModel{Distributions.Univariate, Distributions.Continuous, Distributions.Cauchy, Distributions.Categorical{Float64, Vector{Float64}}}}(0.0, 1.0, 0.8450801042502032, 0.0, SimpleSelector(), MixtureModel{Distributions.Cauchy}(K = 2)
components[1] (prior = 0.5000): Distributions.Cauchy{Float64}(μ=0.65, σ=0.1)
components[2] (prior = 0.5000): Distributions.Cauchy{Float64}(μ=1.0, σ=0.1)
)</code></pre><pre><code class="language-julia-repl hljs">julia&gt; using GlobalOptimization
julia&gt; using Distributions
julia&gt; params = MutationParameters(Rand1(); dist=Normal(0.5, 0.1))
MutationParameters{GlobalOptimization.RandomAdaptation, Rand1, SimpleSelector, Normal{Float64}}(0.0, 1.0, 0.5061103661726901, 0.0, SimpleSelector(), Normal{Float64}(μ=0.5, σ=0.1))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/DE/mutation.jl#L348-L398">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.SelfMutationParameters" href="#GlobalOptimization.SelfMutationParameters"><code>GlobalOptimization.SelfMutationParameters</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">SelfMutationParameters{
    AS&lt;:AbstractAdaptationStrategy,
    MS&lt;:AbstractMutationOperator,
    S&lt;:AbstractSelector,
    D,
}</code></pre><p>The parameters for a DE mutation strategy that applies a mutation strategy with unique parameters for each candidate in the population.</p><p><strong>Fields</strong></p><ul><li><code>Fs::Vector{SVector{4,Float64}}</code>: The mutation parameters for each candidate in the   population. Each element of the vector is an SVector{4} containing the F₁, F₂, F₃, and   F₄ weights for the unified mutation strategy.</li><li><code>sel&lt;:AbstractSelector</code>: The selector used to select the candidates considered in mutation.</li><li><code>dist&lt;:Distribution{Univariate,Continuous}</code>: The distribution used to adapt the mutation   parameters. Note that this should generally be a distribution from   <a href="https://juliastats.org/Distributions.jl/latest/">Distributions.jl</a>, but the only strict   requirement is that rand(dist) returns a floating point value.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/DE/mutation.jl#L409-L429">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.SelfMutationParameters-Tuple{GlobalOptimization.AbstractMutationOperator}" href="#GlobalOptimization.SelfMutationParameters-Tuple{GlobalOptimization.AbstractMutationOperator}"><code>GlobalOptimization.SelfMutationParameters</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">SelfMutationParameters(
    strategy::MS;
    dist=default_mutation_dist,
    sel=SimpleSelector(),
)</code></pre><p>Creates a SelfMutationParameters object with the specified mutation strategy and mutation parameter random adaptation. The mutation parameters are adaptively sampled from the provided <code>dist</code>, clamped to the range (0, 1].</p><p><strong>Arguments</strong></p><ul><li><code>strategy::MS</code>: The mutation strategy to use. This should be one of the mutation   strategies defined in this module (e.g., <code>Rand1</code>, <code>Best2</code>, etc.).</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><p><code>dist::Distribution{Univariate,Continuous}</code>: The distribution used to adapt the   mutation parameters each iteration. Note that this should generally be a   distribution from   <a href="https://juliastats.org/Distributions.jl/latest/">Distributions.jl</a>, but the only   strict requirement is that rand(dist) returns a floating point value. Defaults to   <code>GlobalOptimization.default_mutation_dist</code>, which is a mixture model comprised of   two Cauchy distributions, with probability density given by:</p><p><span>$f_{mix}(x; \mu, \sigma) = 0.5 f(x;\mu_1,\sigma_1) + 0.5 f(x;\mu_2,\sigma_2)$</span>.</p><p>where <span>$\mu = \{0.65, 1.0\}$</span> and <span>$\sigma = \{0.1, 0.1\}$</span>.</p></li><li><p><code>sel::AbstractSelector</code>: The selector used to select the candidates considered in   mutation. Defaults to <code>SimpleSelector()</code>.</p></li></ul><p><strong>Returns</strong></p><ul><li><code>SelfMutationParameters{RandomAdaptation,typeof(strategy),typeof(sel),typeof(dist)}</code>:   A mutation parameters object with the specified mutation strategy and selector.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using GlobalOptimization
julia&gt; params = SelfMutationParameters(Rand1())
SelfMutationParameters{GlobalOptimization.RandomAdaptation, Rand1, SimpleSelector, MixtureModel{Univariate, Continuous, Cauchy, Categorical{Float64, Vector{Float64}}}}(StaticArraysCore.SVector{4, Float64}[], SimpleSelector(), MixtureModel{Cauchy}(K = 2)
components[1] (prior = 0.5000): Cauchy{Float64}(μ=0.65, σ=0.1)
components[2] (prior = 0.5000): Cauchy{Float64}(μ=1.0, σ=0.1)
)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/DE/mutation.jl#L437-L481">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.Rand1" href="#GlobalOptimization.Rand1"><code>GlobalOptimization.Rand1</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Rand1</code></pre><p>The DE/rand/1 mutation strategy given by:</p><p><span>$\mathbf{v}_i = \mathbf{x}_{r_1} + F\left(\mathbf{x}_{r_2} - \mathbf{x}_{r_3}\right)$</span></p><p>where <span>$\mathbf{v}_i$</span> is the target (<span>$i$</span>-th) mutant, <span>$\mathbf{x}_j$</span> denotes the <span>$j$</span>-th candidate, <span>$F$</span> is a scaling factor, and <span>$r_1$</span>, <span>$r_2$</span>, and <span>$r_3$</span> are randomly selected integers in the set returned by the selector.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/DE/mutation.jl#L15-L25">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.Rand2" href="#GlobalOptimization.Rand2"><code>GlobalOptimization.Rand2</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Rand2</code></pre><p>The DE/rand/2 mutation strategy given by:</p><p><span>$\mathbf{v}_i = \mathbf{x}_{r_1} + F\left(\mathbf{x}_{r_2} - \mathbf{x}_{r_3}\right) + F\left(\mathbf{x}_{r_4} - \mathbf{x}_{r_5}\right)$</span></p><p>where <span>$\mathbf{v}_i$</span> is the target (<span>$i$</span>-th) mutant, <span>$\mathbf{x}_j$</span> denotes the <span>$j$</span>-th candidate, <span>$F$</span> is a scaling factor, and <span>$r_1$</span>, <span>$r_2$</span>, <span>$r_3$</span>, <span>$r_4$</span>, and <span>$r_5$</span> are randomly selected integers in the set returned by the selector.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/DE/mutation.jl#L28-L40">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.Best1" href="#GlobalOptimization.Best1"><code>GlobalOptimization.Best1</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Best1</code></pre><p>The DE/best/1 mutation strategy given by:</p><p><span>$\mathbf{v}_i = \mathbf{x}_{b} + F\left(\mathbf{x}_{r_1} - \mathbf{x}_{r_2}\right)$</span></p><p>where <span>$\mathbf{v}_i$</span> is the target (<span>$i$</span>-th) mutant, <span>$\mathbf{x}_j$</span> denotes the <span>$j$</span>-th candidate, <span>$F$</span> is a scaling factor, subscript <span>$b$</span> denotes the best candidate (in terms of the objective/fitness function), and <span>$r_1$</span> and <span>$r_2$</span> are randomly selected integers in the set returned by the selector.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/DE/mutation.jl#L43-L54">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.Best2" href="#GlobalOptimization.Best2"><code>GlobalOptimization.Best2</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Best2</code></pre><p>The DE/best/2 mutation strategy given by:</p><p><span>$\mathbf{v}_i = \mathbf{x}_{b} + F\left(\mathbf{x}_{r_1} - \mathbf{x}_{r_2}\right) + F\left(\mathbf{x}_{r_3} - \mathbf{x}_{r_4}\right)$</span></p><p>where <span>$\mathbf{v}_i$</span> is the target (<span>$i$</span>-th) mutant, <span>$\mathbf{x}_j$</span> denotes the <span>$j$</span>-th candidate, <span>$F$</span> is a scaling factor, subscript <span>$b$</span> denotes the best candidate, and <span>$r_1$</span>, <span>$r_2$</span>, <span>$r_3$</span>, and <span>$r_4$</span> are randomly selected integers in the set returned by the selector.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/DE/mutation.jl#L57-L69">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.CurrentToBest1" href="#GlobalOptimization.CurrentToBest1"><code>GlobalOptimization.CurrentToBest1</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">CurrentToBest1</code></pre><p>The DE/current-to-best/1 mutation strategy given by:</p><p><span>$\mathbf{v}_i = \mathbf{x}_{i} + F_{cr}\left(\mathbf{x}_{b} - \mathbf{x}_{i}\right) + F\left(\mathbf{x}_{r_1} - \mathbf{x}_{r_2}\right)$</span></p><p>where <span>$\mathbf{v}_i$</span> is the target (<span>$i$</span>-th) mutant, <span>$\mathbf{x}_j$</span> denotes the <span>$j$</span>-th candidate, <span>$F_{cs}$</span> and <span>$F$</span> are a scaling factors, subscript <span>$b$</span> denotes the best candidate, and <span>$r_1$</span> and <span>$r_2$</span> are randomly selected integers in the set returned by the selector.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/DE/mutation.jl#L72-L84">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.CurrentToBest2" href="#GlobalOptimization.CurrentToBest2"><code>GlobalOptimization.CurrentToBest2</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">CurrentToBest2</code></pre><p>The DE/current-to-best/2 mutation strategy given by:</p><p><span>$\mathbf{v}_i = \mathbf{x}_{i} + F_{cr}\left(\mathbf{x}_{b} - \mathbf{x}_{i}\right) + F\left(\mathbf{x}_{r_1} - \mathbf{x}_{r_2}\right) + F\left(\mathbf{x}_{r_3} - \mathbf{x}_{r_4}\right)$</span></p><p>where <span>$\mathbf{v}_i$</span> is the target (<span>$i$</span>-th) mutant, <span>$\mathbf{x}_j$</span> denotes the <span>$j$</span>-th candidate, <span>$F_{cs}$</span> and <span>$F$</span> are a scaling factors, subscript <span>$b$</span> denotes the best candidate, and <span>$r_1$</span>, <span>$r_2$</span>, <span>$r_3$</span>, and <span>$r_4$</span> are randomly selected integers in the set returned by the selector.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/DE/mutation.jl#L87-L100">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.CurrentToRand1" href="#GlobalOptimization.CurrentToRand1"><code>GlobalOptimization.CurrentToRand1</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">CurrentToRand1</code></pre><p>The DE/current-to-rand/1 mutation strategy given by:</p><p><span>$\mathbf{v}_i = \mathbf{x}_{i} + F_{cr}\left(\mathbf{x}_{r_1} - \mathbf{x}_{i}\right) + F\left(\mathbf{x}_{r_2} - \mathbf{x}_{r_3}\right)$</span></p><p>where <span>$\mathbf{v}_i$</span> is the target (<span>$i$</span>-th) mutant, <span>$\mathbf{x}_j$</span> denotes the <span>$j$</span>-th candidate, <span>$F_{cs}$</span> and <span>$F$</span> are a scaling factors, and <span>$r_1$</span>, <span>$r_2$</span>, and <span>$r_3$</span> are randomly selected integers in the set returned by the selector.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/DE/mutation.jl#L103-L114">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.CurrentToRand2" href="#GlobalOptimization.CurrentToRand2"><code>GlobalOptimization.CurrentToRand2</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">CurrentToRand2</code></pre><p>The DE/current-to-rand/2 mutation strategy given by:</p><p><span>$\mathbf{v}_i = \mathbf{x}_{i} + F_{cr}\left(\mathbf{x}_{r_1} - \mathbf{x}_{i}\right) + F\left(\mathbf{x}_{r_2} - \mathbf{x}_{r_3}\right) + F\left(\mathbf{x}_{r_4} - \mathbf{x}_{r_5}\right)$</span></p><p>where <span>$\mathbf{v}_i$</span> is the target (<span>$i$</span>-th) mutant, <span>$\mathbf{x}_j$</span> denotes the <span>$j$</span>-th candidate, <span>$F_{cs}$</span> and <span>$F$</span> are a scaling factors, and <span>$r_1$</span>, <span>$r_2$</span>, <span>$r_3$</span>, <span>$r_4$</span>, and <span>$r_5$</span> are randomly selected integers in the set returned by the selector.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/DE/mutation.jl#L117-L130">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.RandToBest1" href="#GlobalOptimization.RandToBest1"><code>GlobalOptimization.RandToBest1</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">RandToBest1</code></pre><p>The DE/rand-to-best/1 mutation strategy given by:</p><p><span>$\mathbf{v}_i = \mathbf{x}_{r_1} + F_{cr}\left(\mathbf{x}_{b} - \mathbf{x}_i\right) + F\left(\mathbf{x}_{r_2} - \mathbf{x}_{r_3}\right)$</span></p><p>where <span>$\mathbf{v}_i$</span> is the target (<span>$i$</span>-th) mutant, <span>$\mathbf{x}_j$</span> denotes the <span>$j$</span>-th candidate, <span>$F_{cs}$</span> and <span>$F$</span> are a scaling factors, subscript <span>$b$</span> denotes the best candidate, and <span>$r_1$</span>, <span>$r_2$</span>, and <span>$r_3$</span> are randomly selected integers in the set returned by the selector.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/DE/mutation.jl#L133-L145">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.RandToBest2" href="#GlobalOptimization.RandToBest2"><code>GlobalOptimization.RandToBest2</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">RandToBest2</code></pre><p>The DE/rand-to-best/2 mutation strategy given by:</p><p><span>$\mathbf{v}_i = \mathbf{x}_{r_1} + F_{cr}\left(\mathbf{x}_{b} - \mathbf{x}_i\right) + F\left(\mathbf{x}_{r_2} - \mathbf{x}_{r_3}\right) + F\left(\mathbf{x}_{r_4} - \mathbf{x}_{r_5}\right)$</span></p><p>where <span>$\mathbf{v}_i$</span> is the target (<span>$i$</span>-th) mutant, <span>$\mathbf{x}_j$</span> denotes the <span>$j$</span>-th candidate, <span>$F_{cs}$</span> and <span>$F$</span> are a scaling factors, subscript <span>$b$</span> denotes the best candidate, and <span>$r_1$</span>, <span>$r_2$</span>, <span>$r_3$</span>, <span>$r_4$</span>, and <span>$r_5$</span> are randomly selected integers in the set returned by the selector.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/DE/mutation.jl#L148-L161">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.Unified" href="#GlobalOptimization.Unified"><code>GlobalOptimization.Unified</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Unified</code></pre><p>The unified DE mutation strategy proposed by Ji Qiang and Chad Mitchell in &quot;A Unified Differential Evolution Algorithm for Global Optimization,&quot; 2014, <a href="https://www.osti.gov/servlets/purl/1163659">https://www.osti.gov/servlets/purl/1163659</a>.</p><p>This mutation strategy is given by:</p><p><span>$\mathbf{v}_i = \mathbf{x}_i + F_1\left(\mathbf{x}_b - \mathbf{x}_i\right) + F_2\left(\mathbf{x}_{r_1} - \mathbf{x}_i\right) + F_3\left(\mathbf{x}_{r_2} - \mathbf{x}_{r_3}\right) + F_4\left(\mathbf{x}_{r_4} - \mathbf{x}_{r_5}\right)$</span></p><p>where <span>$\mathbf{v}_i$</span> is the target (<span>$i$</span>-th) mutant, <span>$\mathbf{x}_j$</span> denotes the <span>$j$</span>-th candidate, <span>$F_1$</span>, <span>$F_2$</span>, <span>$F_3$</span>, and <span>$F_4$</span> are scaling factors, subscript <span>$b$</span> denotes the best candidate, and <span>$r_1$</span>, <span>$r_2$</span>, <span>$r_3$</span>, <span>$r_4$</span>, and <span>$r_5$</span> are randomly selected integers in the set returned by the selector.</p><p>Note that in the underlying implementation, all mutation strategies are implemented with this formulation, where each unique strategy has a different set of <span>$\{F_i : i \in \{1,2,3,4\}\}$</span> that are set to 0.0.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/DE/mutation.jl#L164-L186">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.SimpleSelector" href="#GlobalOptimization.SimpleSelector"><code>GlobalOptimization.SimpleSelector</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">SimpleSelector</code></pre><p>A selector that simply <em>selects</em> all candidates in the population.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/DE/util.jl#L52-L56">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.RadiusLimitedSelector" href="#GlobalOptimization.RadiusLimitedSelector"><code>GlobalOptimization.RadiusLimitedSelector</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">RadiusLimitedSelector</code></pre><p>A selector that selects candidates within a given radius of the target candidate.</p><p>For example, for population size of 10 and a radius of 2, the following will be selected for the given target indices:</p><p><code>target = 5</code> will select <code>[3, 4, 5, 6, 7]</code></p><p><code>target = 1</code> will select <code>[9, 10, 1, 2, 3]</code></p><p><code>target = 9</code> will select <code>[7, 8, 9, 10, 1]</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/DE/util.jl#L59-L72">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.RandomSubsetSelector" href="#GlobalOptimization.RandomSubsetSelector"><code>GlobalOptimization.RandomSubsetSelector</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">RandomSubsetSelector</code></pre><p>A selector that selects a random subset of candidates from the population. The size of the subset is determined by the <code>size</code> parameter.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/DE/util.jl#L83-L88">source</a></section></article><h4 id="DE-Crossover-Strategies"><a class="docs-heading-anchor" href="#DE-Crossover-Strategies">DE Crossover Strategies</a><a id="DE-Crossover-Strategies-1"></a><a class="docs-heading-anchor-permalink" href="#DE-Crossover-Strategies" title="Permalink"></a></h4><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.BinomialCrossoverParameters" href="#GlobalOptimization.BinomialCrossoverParameters"><code>GlobalOptimization.BinomialCrossoverParameters</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">BinomialCrossoverParameters{
    AS&lt;:AbstractAdaptationStrategy,
    T&lt;:AbstractCrossoverTransformation,
    D,
}</code></pre><p>The parameters for a DE binomial crossover strategy.</p><p><strong>Fields</strong></p><ul><li><code>CR::Float64</code>: The crossover rate.</li><li><code>transform::T</code>: The transformation to apply to the candidate and mutant.</li><li><code>dist&lt;:Distribution{Univariate,Continuous}</code>: The distribution used to adapt the crossover   rate parameter. Note that this should generally be a distribution from   <a href="https://juliastats.org/Distributions.jl/stable/">Distributions.jl</a>, but the only   strict requirement is that rand(dist) returns a floating point value.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/DE/crossover.jl#L344-L360">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.BinomialCrossoverParameters-Tuple{Float64}" href="#GlobalOptimization.BinomialCrossoverParameters-Tuple{Float64}"><code>GlobalOptimization.BinomialCrossoverParameters</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">BinomialCrossoverParameters(CR::Float64; transform=NoTransformation())</code></pre><p>Creates a <code>BinomialCrossoverParameters</code> object with a fixed crossover rate <code>CR</code> and optional transformation <code>transform</code>.</p><p><strong>Arguments</strong></p><ul><li><code>CR::Float64</code>: The crossover rate.</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>transform::AbstractCrossoverTransformation</code>: The transformation to apply to the   candidate and mutant. Defaults to <code>NoTransformation()</code>.</li></ul><p><strong>Returns</strong></p><ul><li><code>BinomialCrossoverParameters{NoAdaptation,typeof(transform),Nothing}</code>: A   <code>BinomialCrossoverParameters</code> object with a fixed crossover rate and the optionally   specified transformation.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using GlobalOptimization
julia&gt; params = BinomialCrossoverParameters(0.5)
BinomialCrossoverParameters{GlobalOptimization.NoAdaptation, GlobalOptimization.NoTransformation, Nothing}(0.5, GlobalOptimization.NoTransformation(), nothing)</code></pre><pre><code class="language-julia-repl hljs">julia&gt; using GlobalOptimization
julia&gt; params = BinomialCrossoverParameters(0.5, transform=CovarianceTransformation(0.5, 0.5, 10))
BinomialCrossoverParameters{GlobalOptimization.NoAdaptation, CovarianceTransformation, Nothing}(0.5, CovarianceTransformation(0.5, 0.5, [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]), nothing)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/DE/crossover.jl#L368-L397">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.BinomialCrossoverParameters-Tuple{}" href="#GlobalOptimization.BinomialCrossoverParameters-Tuple{}"><code>GlobalOptimization.BinomialCrossoverParameters</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">BinomialCrossoverParameters(; dist=default_binomial_crossover_dist, transform=NoTransformation())</code></pre><p>Creates a <code>BinomialCrossoverParameters</code> object with an adaptive crossover rate and optional transformation <code>transform</code>.</p><p><strong>Keyword Arguments</strong></p><ul><li><p><code>dist::Distribution{Univariate,Continuous}</code>: The distribution used to adapt the   crossover rate parameter. Note that this should generally be a distribution from   <a href="https://juliastats.org/Distributions.jl/stable/">Distributions.jl</a>, but the only   strict requirement is that rand(dist) returns a floating point value. Defaults to   <code>default_binomial_crossover_dist</code>, which is a mixture model comprised of two Cauchy   distributions, with probability density given by:</p><p><span>$f_{mix}(x; \mu, \sigma) = 0.5 f(x;\mu_1,\sigma_1) + 0.5 f(x;\mu_2,\sigma_2)$</span></p><p>where <span>$\mu = \{0.1, 0.95\}$</span> and <span>$\sigma = \{0.1, 0.1\}$</span>.</p></li><li><p><code>transform::AbstractCrossoverTransformation</code>: The transformation to apply to the   candidate and mutant. Defaults to <code>NoTransformation()</code>.</p></li></ul><p><strong>Returns</strong></p><ul><li><code>BinomialCrossoverParameters{RandomAdaptation,typeof(transform),typeof(dist)}</code>: A   <code>BinomialCrossoverParameters</code> object with an adaptive crossover rate and the   optionally specified transformation.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using GlobalOptimization
julia&gt; params = BinomialCrossoverParameters()
BinomialCrossoverParameters{GlobalOptimization.RandomAdaptation, GlobalOptimization.NoTransformation, Distributions.MixtureModel{Distributions.Univariate, Distributions.Continuous, Distributions.Cauchy, Distributions.Categorical{Float64, Vector{Float64}}}}(0.0, GlobalOptimization.NoTransformation(), MixtureModel{Distributions.Cauchy}(K = 2)
components[1] (prior = 0.5000): Distributions.Cauchy{Float64}(μ=0.1, σ=0.1)
components[2] (prior = 0.5000): Distributions.Cauchy{Float64}(μ=0.95, σ=0.1)
)</code></pre><pre><code class="language-julia-repl hljs">julia&gt; using GlobalOptimization
julia&gt; params = BinomialCrossoverParameters(transform=CovarianceTransformation(0.5, 0.5, 10))
BinomialCrossoverParameters{GlobalOptimization.RandomAdaptation, CovarianceTransformation, Distributions.MixtureModel{Distributions.Univariate, Distributions.Continuous, Distributions.Cauchy, Distributions.Categorical{Float64, Vector{Float64}}}}(0.0, CovarianceTransformation(0.5, 0.5, [2.195780764e-314 2.2117846174e-314 … 2.1293782266e-314 1.5617889024864e-311; 2.366805627e-314 2.316670011e-314 … 2.3355803934e-314 1.4259811738567e-311; … ; 2.195781025e-314 2.195781096e-314 … 1.4531427176862e-310 1.27319747493e-313; 2.366805627e-314 2.366805627e-314 … 1.0270459628367e-310 2.121995795e-314], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]), MixtureModel{Distributions.Cauchy}(K = 2)
components[1] (prior = 0.5000): Distributions.Cauchy{Float64}(μ=0.1, σ=0.1)
components[2] (prior = 0.5000): Distributions.Cauchy{Float64}(μ=0.95, σ=0.1)
)</code></pre><pre><code class="language-julia-repl hljs">julia&gt; using GlobalOptimization
julia&gt; using Distributions
julia&gt; params = BinomialCrossoverParameters(dist=Uniform(0.0, 1.0))
BinomialCrossoverParameters{GlobalOptimization.RandomAdaptation, GlobalOptimization.NoTransformation, Uniform{Float64}}(0.0, GlobalOptimization.NoTransformation(), Uniform{Float64}(a=0.0, b=1.0))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/DE/crossover.jl#L402-L451">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.SelfBinomialCrossoverParameters" href="#GlobalOptimization.SelfBinomialCrossoverParameters"><code>GlobalOptimization.SelfBinomialCrossoverParameters</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">SelfBinomialCrossoverParameters{
    AS&lt;:AbstractAdaptationStrategy,
    T&lt;:AbstractCrossoverTransformation,
    D,
}</code></pre><p>The parameters for a DE self-adaptive binomial crossover strategy.</p><p><strong>Fields</strong></p><ul><li><code>CRs::Vector{Float64}</code>: The crossover rates for each candidate in the population.</li><li><code>transform::T</code>: The transformation to apply to the candidate and mutant.</li><li><code>dist&lt;:Distribution{Univariate,Continuous}</code>: The distribution used to adapt the crossover   rate parameter. Note that this should generally be a distribution from   <a href="https://juliastats.org/Distributions.jl/stable/">Distributions.jl</a>, but the only   strict requirement is that rand(dist) returns a floating point value.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/DE/crossover.jl#L459-L475">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.SelfBinomialCrossoverParameters-Tuple{}" href="#GlobalOptimization.SelfBinomialCrossoverParameters-Tuple{}"><code>GlobalOptimization.SelfBinomialCrossoverParameters</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">SelfBinomialCrossoverParameters(;
    dist=default_binomial_crossover_dist,
    transform=NoTransformation()
)</code></pre><p>Creates a <code>SelfBinomialCrossoverParameters</code> object with an adaptive crossover rate for each candidate in the population and an optional transformation <code>transform</code>.</p><p><strong>Keyword Arguments</strong></p><ul><li><p><code>dist::Distribution{Univariate,Continuous}</code>: The distribution used to adapt the   crossover rate parameter. Note that this should generally be a distribution from   <a href="https://juliastats.org/Distributions.jl/stable/">Distributions.jl</a>, but the only   strict requirement is that rand(dist) returns a floating point value. Defaults to   <code>default_binomial_crossover_dist</code>, which is a mixture model comprised of two Cauchy   distributions, with probability density given by:</p><p><span>$f_{mix}(x; \mu, \sigma) = 0.5 f(x;\mu_1,\sigma_1) + 0.5 f(x;\mu_2,\sigma_2)$</span></p><p>where <span>$\mu = \{0.1, 0.95\}$</span> and <span>$\sigma = \{0.1, 0.1\}$</span>.</p></li><li><p><code>transform::AbstractCrossoverTransformation</code>: The transformation to apply to the   candidate and mutant. Defaults to <code>NoTransformation()</code>.</p></li></ul><p><strong>Returns</strong></p><ul><li><code>SelfBinomialCrossoverParameters{RandomAdaptation,typeof(transform),typeof(dist)}</code>: A   <code>SelfBinomialCrossoverParameters</code> object with an adaptive crossover rate for each   candidate and the optionally specified transformation.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using GlobalOptimization
julia&gt; params = SelfBinomialCrossoverParameters()
SelfBinomialCrossoverParameters{GlobalOptimization.RandomAdaptation, GlobalOptimization.NoTransformation, MixtureModel{Univariate, Continuous, Cauchy, Categorical{Float64, Vector{Float64}}}}(Float64[], GlobalOptimization.NoTransformation(), MixtureModel{Cauchy}(K = 2)
components[1] (prior = 0.5000): Cauchy{Float64}(μ=0.1, σ=0.1)
components[2] (prior = 0.5000): Cauchy{Float64}(μ=0.95, σ=0.1)
)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/DE/crossover.jl#L483-L520">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.CovarianceTransformation" href="#GlobalOptimization.CovarianceTransformation"><code>GlobalOptimization.CovarianceTransformation</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">CovarianceTransformation{T&lt;:AbstractCrossoverTransformation}</code></pre><p>A transformation for performing crossover in the eigen-space of the covariance matrix of the best candidates in the population.</p><p>This is an implementation of the method proposed by Wang and Li in &quot;Differential Evolution Based on Covariance Matrix Learning and Bimodal Distribution Parameter Setting, &quot; 2014, DOI: <a href="https://doi.org/10.1016/j.asoc.2014.01.038">10.1016/j.asoc.2014.01.038</a>.</p><p><strong>Fields</strong></p><ul><li><code>ps::Float64</code>: The proportion of candidates to consider in the covariance matrix. That is,   for a population size of <code>N</code>, the covariance matrix is calculated using the   <code>clamp(ceil(ps * N), 2, N)</code> best candidates.</li><li><code>pb::Float64</code>: The probability of applying the transformation.</li><li><code>B::Matrix{Float64}</code>: The real part of the eigenvectors of the covariance matrix.</li><li><code>ct::Vector{Float64}</code>: The transformed candidate.</li><li><code>mt::Vector{Float64}</code>: The transformed mutant.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/DE/crossover.jl#L54-L72">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.CovarianceTransformation-Tuple{Any, Any, Any}" href="#GlobalOptimization.CovarianceTransformation-Tuple{Any, Any, Any}"><code>GlobalOptimization.CovarianceTransformation</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">CovarianceTransformation(ps::Float64, pb::Float64, num_dims::Int)</code></pre><p>Creates a <code>CovarianceTransformation</code> object with the specified proportion of candidates to consider in the covariance matrix <code>ps</code>, the probability of applying the transformation <code>pb</code>, and the number of dimensions <code>num_dims</code>.</p><p>This is an implementation of the method proposed by Wang and Li in &quot;Differential Evolution Based on Covariance Matrix Learning and Bimodal Distribution Parameter Setting, &quot; 2014, DOI: <a href="https://doi.org/10.1016/j.asoc.2014.01.038">10.1016/j.asoc.2014.01.038</a>.</p><p><strong>Arguments</strong></p><ul><li><code>ps::Float64</code>: The proportion of candidates to consider in the covariance matrix.</li><li><code>pb::Float64</code>: The probability of applying the transformation.</li><li><code>num_dims::Int</code>: The number of dimensions in the search space.</li></ul><p><strong>Returns</strong></p><ul><li><code>CovarianceTransformation</code>: A <code>CovarianceTransformation</code> object with the specified   parameters.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using GlobalOptimization
julia&gt; transformation = CovarianceTransformation(0.5, 0.5, 10)
CovarianceTransformation(0.5, 0.5, [2.3352254645e-314 6.3877104275e-314 … 1.0e-323 5.0e-324; 6.3877051114e-314 6.3877104196e-314 … 6.3877054276e-314 6.387705455e-314; … ; 2.3352254645e-314 2.333217732e-314 … 0.0 6.3877095184e-314; 6.387705143e-314 2.130067282e-314 … 6.387705459e-314 6.387705463e-314], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/DE/crossover.jl#L85-L111">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.UncorrelatedCovarianceTransformation" href="#GlobalOptimization.UncorrelatedCovarianceTransformation"><code>GlobalOptimization.UncorrelatedCovarianceTransformation</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">UncorrelatedCovarianceTransformation{T&lt;:AbstractCrossoverTransformation}</code></pre><p>A transformation for performing crossover in the eigen-space of the covariance matrix of the best candidates in the population which are also not too closely correlated.</p><p>This is an implementation of the method proposed by Wang and Li in &quot;Differential Evolution Based on Covariance Matrix Learning and Bimodal Distribution Parameter Setting, &quot; 2014, DOI: <a href="https://doi.org/10.1016/j.asoc.2014.01.038">10.1016/j.asoc.2014.01.038</a>.</p><p>Correlation alteration based on &quot;Covariance Matrix Learning Differential Evolution Algorithm Based on Correlation&quot; DOI: https://doi.org/10.4236/ijis.2021.111002</p><p><strong>Fields</strong></p><ul><li><code>ps::Float64</code>: The proportion of candidates to consider in the covariance matrix. That is,   for a population size of <code>N</code> with <code>M</code> candidates remaining after the correlation check, the covariance matrix is calculated using the   <code>clamp(ceil(ps * M), 2, M)</code> best candidates.</li><li><code>pb::Float64</code>: The probability of applying the transformation.</li><li><code>a::Float64</code>: The correlation threshold for which two candidates are considered &#39;too close&#39; to both be used in the covariance matrix construction.</li><li><code>B::Matrix{Float64}</code>: The real part of the eigenvectors of the covariance matrix.</li><li><code>ct::Vector{Float64}</code>: The transformed candidate.</li><li><code>mt::Vector{Float64}</code>: The transformed mutant.</li><li><code>idxs::Vector{UInt16}</code>: A vector of indexes for the population</li><li><code>cidxs::Vector{UInt16}</code>: A vector of unique <code>correlated</code> indexes for the population set for removal</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/DE/crossover.jl#L124-L148">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.UncorrelatedCovarianceTransformation-Tuple{Any, Any, Any}" href="#GlobalOptimization.UncorrelatedCovarianceTransformation-Tuple{Any, Any, Any}"><code>GlobalOptimization.UncorrelatedCovarianceTransformation</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">UncorrelatedCovarianceTransformation{T&lt;:AbstractCrossoverTransformation}</code></pre><p>A transformation for performing crossover in the eigen-space of the covariance matrix of the best candidates in the population which are also not too closely correlated.</p><p>This is an implementation of the method proposed by Yuan and Feng in &quot;Covariance Matrix Learning Differential Evolution Algorithm Based on Correlation&quot; DOI: https://doi.org/10.4236/ijis.2021.111002</p><p><strong>Arguments</strong></p><ul><li><code>pb::Float64</code>: The probability of applying the transformation.</li><li><code>a::Float64</code>: The correlation threshold for two candidates being &#39;too close&#39;.</li><li><code>num_dims::Int</code>: The number of dimensions in the search space.</li></ul><p><strong>Keyword Arguments:</strong></p><ul><li><code>ps::Float64</code>: The proportion of candidates to consider in the covariance matrix.   Defaults to 1.0 (i.e., all uncorrelated candidates are considered)</li></ul><p><strong>Returns</strong></p><ul><li><code>UncorrelatedCovarianceTransformation</code>: A <code>UncorrelatedCovarianceTransformation</code> object with the specified   parameters.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using GlobalOptimization
julia&gt; transformation = UncorrelatedCovarianceTransformation(0.5, .95, 10; ps = 1.0)
UncorrelatedCovarianceTransformation(1.0, 0.5, 0.95, [1.0630691323565e-311 1.0630691151907e-311 … 1.063069230316e-311 1.063069119645e-311; 1.0630691158705e-311 1.063069115333e-311 … 1.063069172704e-311 1.0630692904614e-311; … ; 1.063069115428e-311 1.063069114246e-311 … 1.063069124886e-311 1.0630694190924e-311; 1.0630691153804e-311 1.0630691141986e-311 … 1.0630691348624e-311 1.063069428614e-311], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], UInt16[], UInt16[])</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/DE/crossover.jl#L164-L193">source</a></section></article><h3 id="Monotonic-Basin-Hopping"><a class="docs-heading-anchor" href="#Monotonic-Basin-Hopping">Monotonic Basin Hopping</a><a id="Monotonic-Basin-Hopping-1"></a><a class="docs-heading-anchor-permalink" href="#Monotonic-Basin-Hopping" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.MBH" href="#GlobalOptimization.MBH"><code>GlobalOptimization.MBH</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">MBH</code></pre><p>Monotonic Basin Hopping (MBH) algorithm.</p><p>This implementation employs a single candidate rather than a population.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/MBH/MBH.jl#L32-L38">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.MBH-Union{Tuple{GlobalOptimization.AbstractProblem{has_penalty, ContinuousRectangularSearchSpace{T}}}, Tuple{has_penalty}, Tuple{T}} where {T&lt;:Number, has_penalty}" href="#GlobalOptimization.MBH-Union{Tuple{GlobalOptimization.AbstractProblem{has_penalty, ContinuousRectangularSearchSpace{T}}}, Tuple{has_penalty}, Tuple{T}} where {T&lt;:Number, has_penalty}"><code>GlobalOptimization.MBH</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">MBH(prob::AbstractOptimizationProblem{SS}; kwargs...)</code></pre><p>Construct the standard Monotonic Basin Hopping (MBJ) algorithm with the specified options.</p><p><strong>Keyword Arguments</strong></p><ul><li><code>hopper_type::AbstractHopperType</code>: The type of hopper to use. Default is   <code>SingleHopper()</code>.</li><li><code>hop_distribution::AbstractMBHDistribution{T}</code>: The distribution from which hops are   drawn. Default is <code>MBHAdaptiveDistribution{T}(100, 5)</code>.</li><li><code>local_search::AbstractLocalSearch{T}</code>: The local search algorithm to use. Default is   <code>LBFGSLocalSearch{T}()</code>.</li><li><code>initial_space::Union{Nothing,ContinuousRectangularSearchSpace}=nothing</code>: The initial bounds for the search space.</li><li><code>max_iterations::Integer=1000</code>: The maximum number of iterations.</li><li><code>function_tolerance::Real=1e-6</code>: The function tolerance (stall-based stopping criteria).</li><li><code>max_stall_time::Real=60.0</code>: The maximum stall time (in seconds).</li><li><code>max_stall_iterations::Integer=100</code>: The maximum number of stall iterations.</li><li><code>max_time::Real=60.0</code>: The maximum time (in seconds) to allow for optimization.</li><li><code>min_cost::Real=(-Inf)</code>: The minimum cost to allow for optimization.</li><li><code>function_value_check::Union{Val{false},Val{true}}=Val(true)</code>: Whether to check the function value   for bad values (i.e., Inf or NaN).</li><li><code>show_trace::Union{Val{false},Val{true}}=Val(false)</code>: Whether to show the trace.</li><li><code>save_trace::Union{Val{false},Val{true}}=Val(false)</code>: Whether to save the trace.</li><li><code>save_file::String=&quot;trace.txt&quot;</code>: The file to save the trace to.</li><li><code>trace_level::TraceLevel=TraceMinimal(1)</code>: The trace level to use.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/MBH/MBH.jl#L106-L131">source</a></section></article><h4 id="Hopper-Types"><a class="docs-heading-anchor" href="#Hopper-Types">Hopper Types</a><a id="Hopper-Types-1"></a><a class="docs-heading-anchor-permalink" href="#Hopper-Types" title="Permalink"></a></h4><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.MCH" href="#GlobalOptimization.MCH"><code>GlobalOptimization.MCH</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">MCH{EM&lt;:AbstractFunctionEvaluationMethod} &lt;: GlobalOptimization.AbstractHopperType</code></pre><p>Employs the method of <em>Multiple Communicating Hoppers</em> (MCH) to explore the search space as described in Englander, Arnold C., &quot;Speeding-Up a Random Search for the Global Minimum of a Non-Convex, Non-Smooth Objective Function&quot; (2021). <em>Doctoral Dissertations</em>. 2569. <a href="https://scholars.unh.edu/dissertation/2569/">https://scholars.unh.edu/dissertation/2569</a>.</p><p>The struct fields are the same as the constructor arguments.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/MBH/Hopper.jl#L25-L34">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.MCH-Union{Tuple{}, Tuple{EM}} where EM&lt;:GlobalOptimization.AbstractFunctionEvaluationMethod" href="#GlobalOptimization.MCH-Union{Tuple{}, Tuple{EM}} where EM&lt;:GlobalOptimization.AbstractFunctionEvaluationMethod"><code>GlobalOptimization.MCH</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">MCH(;
    num_hoppers::Integer=4,
    eval_method&lt;:AbstractFunctionEvaluationMethod=SerialFunctionEvaluation(),
)</code></pre><p>Constructs a new <code>MCH</code> object with the specified number of hoppers and evaluation method.</p><p><strong>Keyword Arguments</strong></p><ul><li><code>num_hoppers::Integer</code>: The number of hoppers to use. Default is 4.</li><li><code>eval_method&lt;:AbstractFunctionEvaluationMethod</code>: The evaluation method to use. Default   is <code>SerialFunctionEvaluation()</code>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/MBH/Hopper.jl#L39-L51">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.SingleHopper" href="#GlobalOptimization.SingleHopper"><code>GlobalOptimization.SingleHopper</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">SingleHopper &lt;: GlobalOptimization.AbstractHopperType</code></pre><p>A single hopper that is used to explore the search space. Note that no parallelism is employed.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/MBH/Hopper.jl#L17-L22">source</a></section></article><h4 id="Hop-Distributions"><a class="docs-heading-anchor" href="#Hop-Distributions">Hop Distributions</a><a id="Hop-Distributions-1"></a><a class="docs-heading-anchor-permalink" href="#Hop-Distributions" title="Permalink"></a></h4><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.MBHAdaptiveDistribution" href="#GlobalOptimization.MBHAdaptiveDistribution"><code>GlobalOptimization.MBHAdaptiveDistribution</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">MBHAdaptiveDistribution{T}</code></pre><p>An adaptive distribution for MBH. In this implementation, each element of a <em>hop</em> is drawn from a univariate adaptive mixture model comprised of two Laplace distributions as defined in Englander, Arnold C., &quot;Speeding-Up a Random Search for the Global Minimum of a Non-Convex, Non-Smooth Objective Function&quot; (2021). <em>Doctoral Dissertations</em>. 2569. <a href="https://scholars.unh.edu/dissertation/2569/">https://scholars.unh.edu/dissertation/2569</a>.</p><p>The univariate mixture model for the <span>$i$</span>-th element of a hop has a PDF given by:</p><p><span>$f_{\text{mix},i}(x; b, c, \hat{\lambda}_i) = k_i\left[(1 - b) f(x;\mu = 0,\theta = c*\hat{\lambda}_i) + b f(x;\mu = 0, \theta = 1)\right]$</span></p><p>where <span>$\mu$</span> denotes the location parameter and <span>$\theta$</span> the scale parameter of a Laplace distribution (i.e., with probability density <span>$f(x;\mu,\theta)$</span>). Note that <span>$k_i$</span> denotes half of the length of the search space in the <span>$i$</span>-th dimension.</p><p>The scale parameter <span>$\hat{\lambda}_i$</span> is adaptively updated after each successful hop with a low-delay estimate given by:</p><p><span>$\hat{\lambda}_i = (1 - a) \Psi_i + a \hat{\lambda}_i$</span></p><p>Note that <span>$\hat{\lambda}_i$</span> is held constant at <code>λhat0</code> until <code>min_memory_update</code> successful steps have been made. Englander (2021) proposed taking <span>$\Psi_i$</span> to be the standard deviation of the <span>$i$</span>-th element of the last <code>step_memory</code> successful hops. Alternatively, the mean absolute deviation (MAD) around the median of the last <code>step_memory</code> steps can be used. Note that the MAD median is the maximum likelihood estimator for a Laplace distribution&#39;s shape parameter. In this implementation, setting <code>use_mad = true</code> will take <span>$\Psi_i$</span> to be the MAD median, otherwise, the standard deviation is used.</p><p><strong>Fields</strong></p><ul><li><code>step_memory::MBHStepMemoory{T}</code>: The step memory for the distribution</li><li><code>min_memory_update::Int</code>: The minimum number of steps in memory before updating the scale parameter</li><li><code>a</code>: A parameter that defines the influence of a new successful step in the adaptation of   the distribution.</li><li><code>b::T</code>: The mixing parameter for the two Laplace distributions</li><li><code>c::T</code>: The scale parameter for the first Laplace distribution</li><li><code>λhat::Vector{T}</code>: The estimated scale parameter of the first Laplace distribution</li><li><code>λhat0::T</code>: The initial value of the scale parameter</li><li><code>use_mad::Bool</code>: Flag to indicate if we will use the STD (proposed by Englander) or MAD median (MVE) to   update the estimated scale parameter</li><li><code>dim_delta::Vector{T}</code>: The length of the search space in each dimension</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/MBH/Distributions.jl#L180-L222">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.MBHAdaptiveDistribution-Union{Tuple{Int64, Int64}, Tuple{T}} where T" href="#GlobalOptimization.MBHAdaptiveDistribution-Union{Tuple{Int64, Int64}, Tuple{T}} where T"><code>GlobalOptimization.MBHAdaptiveDistribution</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">MBHAdaptiveDistribution{T}(
    memory_len::Int, min_memory_update::Int;
    a=0.93,
    b=0.05,
    c=1.0,
    λhat0=1.0,
) where T</code></pre><p>Creates a new <code>MBHAdaptiveDistribution</code> with the given parameters.</p><p><strong>Arguments</strong></p><ul><li><code>memory_len::Int</code>: The length of the memory for the distribution adaptation.</li><li><code>min_memory_update::Int</code>: The minimum number of steps in memory before updating the scale parameter.</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>a</code>: A parameter that defines the influence of a new successful step in the adaptation of   the distribution.</li><li><code>b</code>: The mixing parameter for the two Laplace distributions</li><li><code>c</code>: The scale parameter for the first Laplace distribution</li><li><code>λhat0</code>: The initial value of the scale parameter</li><li><code>use_mad::Bool</code>: Flag to indicate which metric to use for estimating the scale parameter.   If <code>true</code>, the MAD median is used, which is the maximum likelihood estimator for a   Laplace distribution&#39;s shape parameter. If <code>false</code>, the standard deviation is used   as proposed by Englander (2021).</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/MBH/Distributions.jl#L248-L273">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.MBHStaticDistribution" href="#GlobalOptimization.MBHStaticDistribution"><code>GlobalOptimization.MBHStaticDistribution</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">MBHStaticDistribution{T}</code></pre><p>A static distribution for MBH. In this implementation, each element of a <em>hop</em> is drawn from a mixture model comprised of two Laplace distributions with PDF given by:</p><p><span>$f_{mix}(x; b, \lambda) = k_i\left[(1 - b) f(x;\mu = 0,\theta = \lambda) + b f(x;\mu = 0, \theta = 1)\right]$</span></p><p>where <span>$\mu$</span> denotes the location parameter and <span>$\theta$</span> the scale parameter of a Laplace distribution (i.e., with probability density <span>$f(x;\mu,\theta)$</span>). Additionally, <span>$k_i$</span> is half of the length of the search space in the <span>$i$</span>-th dimension.</p><p><strong>Fields</strong></p><ul><li><code>b::T</code>: The mixing parameter for the two Laplace distributions</li><li><code>λ::T</code>: The scale parameter for the first Laplace distribution in the mixture model</li><li><code>dim_delta::Vector{T}</code>: The length of the search space in each dimension</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/MBH/Distributions.jl#L139-L155">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.MBHStaticDistribution-Union{Tuple{}, Tuple{T}} where T" href="#GlobalOptimization.MBHStaticDistribution-Union{Tuple{}, Tuple{T}} where T"><code>GlobalOptimization.MBHStaticDistribution</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">MBHStaticDistribution{T}(; b=0.05, λ=0.7) where {T}</code></pre><p>Creates a new <code>MBHStaticDistribution</code> with the given parameters.</p><p><strong>Keyword Arguments</strong></p><ul><li><code>b</code>: The mixing parameter for the two Laplace distributions</li><li><code>λ</code>: The scale parameter for the first Laplace distribution in the mixture model</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/MBH/Distributions.jl#L166-L174">source</a></section></article><h4 id="Local-Search-Methods"><a class="docs-heading-anchor" href="#Local-Search-Methods">Local Search Methods</a><a id="Local-Search-Methods-1"></a><a class="docs-heading-anchor-permalink" href="#Local-Search-Methods" title="Permalink"></a></h4><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.LocalStochasticSearch" href="#GlobalOptimization.LocalStochasticSearch"><code>GlobalOptimization.LocalStochasticSearch</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">LocalStochasticSearch{T}</code></pre><p>A local search algorithm that uses a stochastic approach to locally improve the candidate solution.</p><p>Note that this local search algorithm is able to guarantee satisfaction of both the box constraints and the nonlinear inequality constraint (if any).</p><p><strong>Fields</strong></p><ul><li><code>b::T</code>: The local step standard deviation.</li><li><code>iters::Int</code>: The number of iterations to perform.</li><li><code>step::Vector{T}</code>: The candidate step and candidate storage.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/MBH/LocalSearch.jl#L26-L39">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.LocalStochasticSearch-Union{Tuple{T}, Tuple{Real, Int64}} where T&lt;:AbstractFloat" href="#GlobalOptimization.LocalStochasticSearch-Union{Tuple{T}, Tuple{Real, Int64}} where T&lt;:AbstractFloat"><code>GlobalOptimization.LocalStochasticSearch</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">LocalStochasticSearch{T}(b::Real, iters::Int) where {T&lt;:AbstractFloat}</code></pre><p>Create a new <code>LocalStochasticSearch</code> object with the given step size and number of iterations.</p><p><strong>Arguments</strong></p><ul><li><code>b::Real</code>: The local step standard deviation.</li><li><code>iters::Int</code>: The number of iterations to perform.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/MBH/LocalSearch.jl#L50-L58">source</a></section></article><h2 id="Trace-Options"><a class="docs-heading-anchor" href="#Trace-Options">Trace Options</a><a id="Trace-Options-1"></a><a class="docs-heading-anchor-permalink" href="#Trace-Options" title="Permalink"></a></h2><p>Each algorithm provides the ability trace solve information to the terminal  or a specified file through setting the keyword arguments <code>show_trace = Val(true)</code> and <code>save_trace = Val(true)</code>, respectively. Additionally, the amount of information provided in the trace can be controlled by setting the <code>trace_level</code> keyword argument with one of the following <code>TraceLevel</code> constructors:</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.TraceMinimal-Tuple{}" href="#GlobalOptimization.TraceMinimal-Tuple{}"><code>GlobalOptimization.TraceMinimal</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">TraceMinimal(freq)
TraceMinimal(; print_frequency = 1, save_frequency = 1)</code></pre><p>Trace Minimal information about the optimization process.</p><p>For example, this will set <code>PSO</code> or <code>DE</code> to print the elapsed time, iteration number, stall iterations, and global best fitness.</p><p><strong>Returns</strong></p><ul><li><code>TraceLevel{Val{:minimal}}</code>: A trace level object with the minimal trace level.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/tracing.jl#L12-L23">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.TraceDetailed-Tuple{}" href="#GlobalOptimization.TraceDetailed-Tuple{}"><code>GlobalOptimization.TraceDetailed</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">TraceDetailed(freq)
TraceDetailed(; print_frequency = 1, save_frequency = 1)</code></pre><p>Trace Detailed information about the optimization process (including the information in the minimal trace).</p><p><strong>Returns</strong></p><ul><li><code>TraceLevel{Val{:detailed}}</code>: A trace level object with the detailed trace level.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/tracing.jl#L28-L37">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GlobalOptimization.TraceAll-Tuple{}" href="#GlobalOptimization.TraceAll-Tuple{}"><code>GlobalOptimization.TraceAll</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">TraceAll(freq)
TraceAll(; print_frequency = 1, save_frequency = 1)</code></pre><p>Trace All information about the optimization process (including the information in the detailed trace). This trace option should likely only be used for debugging purposes.</p><p><strong>Returns</strong></p><ul><li><code>TraceLevel{Val{:all}}</code>: A trace level object with the all trace level.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/GrantHecht/https://github.com/UB-SSDC-Lab/GlobalOptimization.jl/blob/{commit}{path}#{line}/blob/f8cd02f3b19daadf41f30fa7ab6b58479cc6b859/src/tracing.jl#L42-L51">source</a></section></article><h2 id="Index"><a class="docs-heading-anchor" href="#Index">Index</a><a id="Index-1"></a><a class="docs-heading-anchor-permalink" href="#Index" title="Permalink"></a></h2><ul><li><a href="#GlobalOptimization.Best1"><code>GlobalOptimization.Best1</code></a></li><li><a href="#GlobalOptimization.Best2"><code>GlobalOptimization.Best2</code></a></li><li><a href="#GlobalOptimization.BinomialCrossoverParameters-Tuple{}"><code>GlobalOptimization.BinomialCrossoverParameters</code></a></li><li><a href="#GlobalOptimization.BinomialCrossoverParameters"><code>GlobalOptimization.BinomialCrossoverParameters</code></a></li><li><a href="#GlobalOptimization.BinomialCrossoverParameters-Tuple{Float64}"><code>GlobalOptimization.BinomialCrossoverParameters</code></a></li><li><a href="#GlobalOptimization.CSRNVelocityUpdate-Tuple{}"><code>GlobalOptimization.CSRNVelocityUpdate</code></a></li><li><a href="#GlobalOptimization.CSRNVelocityUpdate"><code>GlobalOptimization.CSRNVelocityUpdate</code></a></li><li><a href="#GlobalOptimization.ContinuousRectangularSearchSpace-Union{Tuple{T2}, Tuple{T1}, Tuple{AbstractVector{T1}, AbstractVector{T2}}} where {T1&lt;:Real, T2&lt;:Real}"><code>GlobalOptimization.ContinuousRectangularSearchSpace</code></a></li><li><a href="#GlobalOptimization.ContinuousRectangularSearchSpace"><code>GlobalOptimization.ContinuousRectangularSearchSpace</code></a></li><li><a href="#GlobalOptimization.CovarianceTransformation-Tuple{Any, Any, Any}"><code>GlobalOptimization.CovarianceTransformation</code></a></li><li><a href="#GlobalOptimization.CovarianceTransformation"><code>GlobalOptimization.CovarianceTransformation</code></a></li><li><a href="#GlobalOptimization.CurrentToBest1"><code>GlobalOptimization.CurrentToBest1</code></a></li><li><a href="#GlobalOptimization.CurrentToBest2"><code>GlobalOptimization.CurrentToBest2</code></a></li><li><a href="#GlobalOptimization.CurrentToRand1"><code>GlobalOptimization.CurrentToRand1</code></a></li><li><a href="#GlobalOptimization.CurrentToRand2"><code>GlobalOptimization.CurrentToRand2</code></a></li><li><a href="#GlobalOptimization.DE-Union{Tuple{GlobalOptimization.AbstractProblem{has_penalty, SS}}, Tuple{has_penalty}, Tuple{SS}, Tuple{T}, Tuple{CP}, Tuple{MP}} where {MP&lt;:GlobalOptimization.AbstractMutationParameters, CP&lt;:GlobalOptimization.AbstractCrossoverParameters, T&lt;:AbstractFloat, SS&lt;:ContinuousRectangularSearchSpace{T}, has_penalty}"><code>GlobalOptimization.DE</code></a></li><li><a href="#GlobalOptimization.DE"><code>GlobalOptimization.DE</code></a></li><li><a href="#GlobalOptimization.LatinHypercubeInitialization-Tuple{Int64}"><code>GlobalOptimization.LatinHypercubeInitialization</code></a></li><li><a href="#GlobalOptimization.LatinHypercubeInitialization"><code>GlobalOptimization.LatinHypercubeInitialization</code></a></li><li><a href="#GlobalOptimization.LocalStochasticSearch"><code>GlobalOptimization.LocalStochasticSearch</code></a></li><li><a href="#GlobalOptimization.LocalStochasticSearch-Union{Tuple{T}, Tuple{Real, Int64}} where T&lt;:AbstractFloat"><code>GlobalOptimization.LocalStochasticSearch</code></a></li><li><a href="#GlobalOptimization.MATLABVelocityUpdate-Tuple{}"><code>GlobalOptimization.MATLABVelocityUpdate</code></a></li><li><a href="#GlobalOptimization.MATLABVelocityUpdate"><code>GlobalOptimization.MATLABVelocityUpdate</code></a></li><li><a href="#GlobalOptimization.MBH-Union{Tuple{GlobalOptimization.AbstractProblem{has_penalty, ContinuousRectangularSearchSpace{T}}}, Tuple{has_penalty}, Tuple{T}} where {T&lt;:Number, has_penalty}"><code>GlobalOptimization.MBH</code></a></li><li><a href="#GlobalOptimization.MBH"><code>GlobalOptimization.MBH</code></a></li><li><a href="#GlobalOptimization.MBHAdaptiveDistribution"><code>GlobalOptimization.MBHAdaptiveDistribution</code></a></li><li><a href="#GlobalOptimization.MBHAdaptiveDistribution-Union{Tuple{Int64, Int64}, Tuple{T}} where T"><code>GlobalOptimization.MBHAdaptiveDistribution</code></a></li><li><a href="#GlobalOptimization.MBHStaticDistribution-Union{Tuple{}, Tuple{T}} where T"><code>GlobalOptimization.MBHStaticDistribution</code></a></li><li><a href="#GlobalOptimization.MBHStaticDistribution"><code>GlobalOptimization.MBHStaticDistribution</code></a></li><li><a href="#GlobalOptimization.MCH"><code>GlobalOptimization.MCH</code></a></li><li><a href="#GlobalOptimization.MCH-Union{Tuple{}, Tuple{EM}} where EM&lt;:GlobalOptimization.AbstractFunctionEvaluationMethod"><code>GlobalOptimization.MCH</code></a></li><li><a href="#GlobalOptimization.MutationParameters-NTuple{4, Any}"><code>GlobalOptimization.MutationParameters</code></a></li><li><a href="#GlobalOptimization.MutationParameters"><code>GlobalOptimization.MutationParameters</code></a></li><li><a href="#GlobalOptimization.MutationParameters-Tuple{GlobalOptimization.AbstractMutationOperator}"><code>GlobalOptimization.MutationParameters</code></a></li><li><a href="#GlobalOptimization.NonlinearLeastSquaresProblem-Union{Tuple{F}, Tuple{has_penalty}, Tuple{T}, Tuple{F, GlobalOptimization.SearchSpace{T}, Int64}} where {T, has_penalty, F&lt;:Function}"><code>GlobalOptimization.NonlinearLeastSquaresProblem</code></a></li><li><a href="#GlobalOptimization.NonlinearLeastSquaresProblem"><code>GlobalOptimization.NonlinearLeastSquaresProblem</code></a></li><li><a href="#GlobalOptimization.NonlinearLeastSquaresProblem-Union{Tuple{F}, Tuple{F, AbstractVector{&lt;:Real}, AbstractVector{&lt;:Real}, Int64}} where F&lt;:Function"><code>GlobalOptimization.NonlinearLeastSquaresProblem</code></a></li><li><a href="#GlobalOptimization.NonlinearLeastSquaresProblem-Union{Tuple{SS}, Tuple{F}, Tuple{F, SS, Int64}} where {F&lt;:Function, SS&lt;:GlobalOptimization.SearchSpace}"><code>GlobalOptimization.NonlinearLeastSquaresProblem</code></a></li><li><a href="#GlobalOptimization.NonlinearProblem-Union{Tuple{F}, Tuple{F, AbstractVector{&lt;:Real}, AbstractVector{&lt;:Real}}} where F&lt;:Function"><code>GlobalOptimization.NonlinearProblem</code></a></li><li><a href="#GlobalOptimization.NonlinearProblem-Union{Tuple{SS}, Tuple{F}, Tuple{F, SS}} where {F&lt;:Function, SS&lt;:GlobalOptimization.SearchSpace}"><code>GlobalOptimization.NonlinearProblem</code></a></li><li><a href="#GlobalOptimization.NonlinearProblem-Union{Tuple{F}, Tuple{has_penalty}, Tuple{T}, Tuple{F, GlobalOptimization.SearchSpace{T}}} where {T, has_penalty, F&lt;:Function}"><code>GlobalOptimization.NonlinearProblem</code></a></li><li><a href="#GlobalOptimization.NonlinearProblem"><code>GlobalOptimization.NonlinearProblem</code></a></li><li><a href="#GlobalOptimization.OptimizationProblem-Union{Tuple{F}, Tuple{has_penalty}, Tuple{T}, Tuple{F, GlobalOptimization.SearchSpace{T}}} where {T, has_penalty, F&lt;:Function}"><code>GlobalOptimization.OptimizationProblem</code></a></li><li><a href="#GlobalOptimization.OptimizationProblem-Union{Tuple{SS}, Tuple{F}, Tuple{F, SS}} where {F&lt;:Function, SS&lt;:GlobalOptimization.SearchSpace}"><code>GlobalOptimization.OptimizationProblem</code></a></li><li><a href="#GlobalOptimization.OptimizationProblem"><code>GlobalOptimization.OptimizationProblem</code></a></li><li><a href="#GlobalOptimization.OptimizationProblem-Union{Tuple{F}, Tuple{F, AbstractVector{&lt;:Real}, AbstractVector{&lt;:Real}}} where F&lt;:Function"><code>GlobalOptimization.OptimizationProblem</code></a></li><li><a href="#GlobalOptimization.PSO-Union{Tuple{GlobalOptimization.AbstractProblem{has_penalty, SS}}, Tuple{has_penalty}, Tuple{SS}, Tuple{T}} where {T&lt;:AbstractFloat, SS&lt;:ContinuousRectangularSearchSpace{T}, has_penalty}"><code>GlobalOptimization.PSO</code></a></li><li><a href="#GlobalOptimization.PSO"><code>GlobalOptimization.PSO</code></a></li><li><a href="#GlobalOptimization.PolyesterFunctionEvaluation-Tuple{}"><code>GlobalOptimization.PolyesterFunctionEvaluation</code></a></li><li><a href="#GlobalOptimization.PolyesterFunctionEvaluation"><code>GlobalOptimization.PolyesterFunctionEvaluation</code></a></li><li><a href="#GlobalOptimization.RadiusLimitedSelector"><code>GlobalOptimization.RadiusLimitedSelector</code></a></li><li><a href="#GlobalOptimization.Rand1"><code>GlobalOptimization.Rand1</code></a></li><li><a href="#GlobalOptimization.Rand2"><code>GlobalOptimization.Rand2</code></a></li><li><a href="#GlobalOptimization.RandToBest1"><code>GlobalOptimization.RandToBest1</code></a></li><li><a href="#GlobalOptimization.RandToBest2"><code>GlobalOptimization.RandToBest2</code></a></li><li><a href="#GlobalOptimization.RandomSubsetSelector"><code>GlobalOptimization.RandomSubsetSelector</code></a></li><li><a href="#GlobalOptimization.SelfBinomialCrossoverParameters"><code>GlobalOptimization.SelfBinomialCrossoverParameters</code></a></li><li><a href="#GlobalOptimization.SelfBinomialCrossoverParameters-Tuple{}"><code>GlobalOptimization.SelfBinomialCrossoverParameters</code></a></li><li><a href="#GlobalOptimization.SelfMutationParameters"><code>GlobalOptimization.SelfMutationParameters</code></a></li><li><a href="#GlobalOptimization.SelfMutationParameters-Tuple{GlobalOptimization.AbstractMutationOperator}"><code>GlobalOptimization.SelfMutationParameters</code></a></li><li><a href="#GlobalOptimization.SerialFunctionEvaluation-Tuple{}"><code>GlobalOptimization.SerialFunctionEvaluation</code></a></li><li><a href="#GlobalOptimization.SerialFunctionEvaluation"><code>GlobalOptimization.SerialFunctionEvaluation</code></a></li><li><a href="#GlobalOptimization.SimpleSelector"><code>GlobalOptimization.SimpleSelector</code></a></li><li><a href="#GlobalOptimization.SingleHopper"><code>GlobalOptimization.SingleHopper</code></a></li><li><a href="#GlobalOptimization.ThreadedFunctionEvaluation"><code>GlobalOptimization.ThreadedFunctionEvaluation</code></a></li><li><a href="#GlobalOptimization.ThreadedFunctionEvaluation-Tuple{}"><code>GlobalOptimization.ThreadedFunctionEvaluation</code></a></li><li><a href="#GlobalOptimization.UncorrelatedCovarianceTransformation"><code>GlobalOptimization.UncorrelatedCovarianceTransformation</code></a></li><li><a href="#GlobalOptimization.UncorrelatedCovarianceTransformation-Tuple{Any, Any, Any}"><code>GlobalOptimization.UncorrelatedCovarianceTransformation</code></a></li><li><a href="#GlobalOptimization.Unified"><code>GlobalOptimization.Unified</code></a></li><li><a href="#GlobalOptimization.TraceAll-Tuple{}"><code>GlobalOptimization.TraceAll</code></a></li><li><a href="#GlobalOptimization.TraceDetailed-Tuple{}"><code>GlobalOptimization.TraceDetailed</code></a></li><li><a href="#GlobalOptimization.TraceMinimal-Tuple{}"><code>GlobalOptimization.TraceMinimal</code></a></li><li><a href="#GlobalOptimization.optimize!-Tuple{GlobalOptimization.AbstractOptimizer}"><code>GlobalOptimization.optimize!</code></a></li></ul></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../">« Home</a><a class="docs-footer-nextpage" href="../../dev/contributing/">Contributing »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.14.1 on <span class="colophon-date" title="Tuesday 16 September 2025 14:13">Tuesday 16 September 2025</span>. Using Julia version 1.11.7.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
